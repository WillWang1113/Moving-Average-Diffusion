{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import torch\n",
    "from src.utils.fourier import dft, idft\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "# from src.utils.filters import MovingAvg\n",
    "from src.utils.fourier import sphere2complex, complex2sphere\n",
    "\n",
    "# def moving_average_freq_response(N, sample_rate, freq):\n",
    "#     omega = 2 * torch.pi * freq / sample_rate\n",
    "#     # SMA coefficients\n",
    "#     b = np.ones(N)\n",
    "#     a = np.array([N] + [0]*(N-1))\n",
    "\n",
    "#     # Calculate the frequency response\n",
    "#     w, h = scipy.signal.freqz(b, a, worN=omega)\n",
    "#     # w *= sample_rate / (2 * np.pi)                      # Convert from rad/sample to Hz\n",
    "#     return h\n",
    "\n",
    "def moving_average_freq_response(N, sample_rate, freq):\n",
    "    omega = 2 * torch.pi * freq / sample_rate\n",
    "    coeff = torch.exp(-1j * omega * (N - 1) / 2) / N\n",
    "    omega = torch.where(omega == 0, 1e-5, omega)\n",
    "    Hw = coeff * torch.sin(omega * N / 2) / torch.sin(omega / 2)\n",
    "    # Hw = Hw*torch.exp(1j*omega*N)\n",
    "    return Hw\n",
    "\n",
    "# def moving_avg(x, N):\n",
    "#     avg = torch.nn.AvgPool1d(kernel_size=N, stride=1)\n",
    "#     front = x[:, 0:1, :].repeat(1, N // 2, 1)\n",
    "#     end = x[:, -1:, :].repeat(1, N - 1 - N // 2, 1)\n",
    "#     x = torch.cat([front, x, end], dim=1)\n",
    "#     x = avg(x.permute(0, 2, 1))\n",
    "#     x = x.permute(0, 2, 1)\n",
    "#     return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 4*torch.pi, 200)\n",
    "sample_rate = len(t)/(t.max()-t.min())\n",
    "x = torch.sin(t) + torch.sin(2*t) + 0.3*torch.sin(12*t) - 10\n",
    "x_freq = torch.fft.rfft(x)\n",
    "\n",
    "theta, phi = complex2sphere(x_freq.real, x_freq.imag)\n",
    "\n",
    "freq = torch.fft.rfftfreq(len(t), 1/sample_rate)\n",
    "mag = x_freq.abs()\n",
    "phase = x_freq.angle()\n",
    "phase[torch.abs(phase) < 1] = 0\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(t, x)\n",
    "axs[1].plot(freq, x_freq.abs())\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "# axs[2].plot(freq, x_freq.angle())\n",
    "# axs[1].plot(freq, theta)\n",
    "# axs[2].plot(freq, phi)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manuplate on the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "h = moving_average_freq_response(N, sample_rate=sample_rate, freq=freq)\n",
    "x_freq_new = x_freq * h\n",
    "# x_freq_new = x_freq * h * torch.exp(torch.tensor(-1j*N))\n",
    "mag = x_freq_new.abs()\n",
    "phase = x_freq_new.angle()\n",
    "x_new = torch.fft.irfft(x_freq_new)\n",
    "x_new_avgpool = torch.nn.functional.avg_pool1d(x.reshape(1,1,-1), N,N).permute(0,2,1)\n",
    "fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(x_new)\n",
    "axs[0].plot(t, x_new)\n",
    "# axs[0].scatter(t[N-1::N],x_new[N-1::N])\n",
    "# axs[0].scatter(t[N-1::N], x_new_avgpool.flatten())\n",
    "axs[1].plot(freq, mag)\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "# axs[2].plot(freq, phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manuplate on the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.filters import MovingAvgTime\n",
    "\n",
    "\n",
    "x_new = MovingAvgTime(N)(x.reshape(1,-1,1))\n",
    "# x_new = np.convolve(np.concatenate([x[-N+1:],x]), np.ones(N)/N, mode='valid')\n",
    "x_freq = torch.fft.rfft(x_new.flatten())\n",
    "freq = torch.fft.rfftfreq(len(t), 1/sample_rate)\n",
    "mag = x_freq.abs()\n",
    "phase = x_freq.angle()\n",
    "\n",
    "# mag = x_freq_new.abs()\n",
    "# phase = x_freq_new.angle()\n",
    "# # print(phase)\n",
    "# x = torch.fft.irfft(x_freq_new)\n",
    "# print(x_new[N//2:-N//2])\n",
    "fig, axs = plt.subplots(3)\n",
    "axs[0].plot(x_new.flatten())\n",
    "axs[1].plot(freq, mag)\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "axs[2].plot(freq, phase)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreqLinear(torch.nn.Module):\n",
    "    def __init__(self, in_channels, fft_len, kernal_size) -> None:\n",
    "        super().__init__()\n",
    "        self.kernel = torch.nn.Parameter(\n",
    "            torch.complex(\n",
    "                torch.ones(fft_len, kernal_size), torch.zeros(fft_len, kernal_size)\n",
    "            ),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(kernal_size * in_channels , in_channels).to(torch.cfloat)\n",
    "        self.in_channels= in_channels\n",
    "        self.fft_len = fft_len\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0,2,1)\n",
    "        x = torch.fft.rfft(x, norm=\"ortho\", dim=1)\n",
    "        x_channels = []\n",
    "        for i in range(x.shape[-1]):\n",
    "            x_channels.append(x[...,[i]] * self.kernel)\n",
    "        x = torch.concat(x_channels, dim=-1)\n",
    "        x = self.linear(x)\n",
    "        # x = self.linear(x.flatten()).reshape(-1, self.fft_len, self.in_channels)\n",
    "        x = torch.fft.irfft(x, norm=\"ortho\", dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimeConv(torch.nn.Module):\n",
    "    def __init__(self, in_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channel, out_channels=in_channel, kernel_size=3, bias=False, padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0,2,1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.sin(torch.arange(288) / 100).reshape(1, -1, 2)\n",
    "m = FreqLinear(in_channels=x.shape[-1], fft_len=x.shape[1]//2+1, kernal_size=10)\n",
    "for p in m.parameters():\n",
    "    print(p.numel())\n",
    "y = torch.ones_like(x)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss = loss_fn(y, m(x))\n",
    "loss.backward()\n",
    "\n",
    "# x = x.repeat(2,1,1)\n",
    "# kernel = torch.rand(x.shape[1] // 2 + 1, 3)\n",
    "# x = torch.fft.rfft(x, dim=1)\n",
    "# print(x)\n",
    "# print(kernel)\n",
    "# print(x.shape)\n",
    "# print(kernel.shape)\n",
    "# x * kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def moving_average_1d(data: torch.Tensor, kernel_size:int, stride:int=1):\n",
    "    # Unfold the data tensor to create a windowed view\n",
    "    unfolded_data = data.unfold(1, kernel_size, stride)\n",
    "    print(unfolded_data.shape)\n",
    "    \n",
    "    # Create a kernel tensor for matrix multiplication\n",
    "    kernel = torch.ones(kernel_size) / kernel_size\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    moving_averages_unfolded = unfolded_data @ kernel\n",
    "    \n",
    "    # # Pad the moving averages tensor to match the original data size\n",
    "    # padding = kernel_size - 1\n",
    "    # moving_averages_padded = torch.cat((torch.zeros(padding), moving_averages_unfolded))\n",
    "    \n",
    "    # Fold the moving averages tensor to get the final result\n",
    "    # moving_averages = moving_averages_padded.view(-1)\n",
    "    \n",
    "    return moving_averages_unfolded\n",
    "\n",
    "# Example usage\n",
    "data = torch.arange(60).float().reshape(2,-1,3)  # 1D tensor with 10 elements\n",
    "kernel_size = 5\n",
    "\n",
    "moving_averages = moving_average_1d(data, kernel_size)\n",
    "print(moving_averages)  # Output: torch.Size([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.schedules.collection import linear_schedule\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "from src.utils.fourier import complex2sphere, sphere2complex\n",
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "\n",
    "\n",
    "# x_norm_fft = torch.fft.rfft(x_norm, dim=1, norm=\"ortho\")\n",
    "# plt.plot(dct(x, norm='ortho').flatten())\n",
    "# plt.yscale('log')\n",
    "\n",
    "# x_norm = (x - x.mean(dim=1)) / torch.sqrt(x.var(dim=1))\n",
    "freq = torch.fft.rfftfreq(x.shape[1])\n",
    "print(freq.shape)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(torch.concat([x_fft.real, x_fft.imag[:,1:-1,:]], dim=1).flatten())\n",
    "# fig.savefig(\"noisy_0.png\")\n",
    "# plt.close()\n",
    "\n",
    "mat = [MovingAvgFreq(i, freq=freq).Hw for i in range(2, x.shape[1] + 1)]\n",
    "mat = torch.concat(mat)\n",
    "fig, axs = plt.subplots(2)\n",
    "for i in range(len(freq)):\n",
    "    axs[0].plot(mat[:,i,:].real)\n",
    "    axs[1].plot(mat[:,i,:].imag)\n",
    "    \n",
    "    \n",
    "# mat = [MovingAvgTime(i) for i in range(2, x.shape[1] + 1)]\n",
    "# T = len(mat)\n",
    "# _, _, alpha_bars = linear_schedule(0, 0, T)\n",
    "# betas = torch.sqrt(1 - alpha_bars)\n",
    "# betas\n",
    "\n",
    "# plt.plot(betas)\n",
    "# for i, degrade_fn in enumerate(mat):\n",
    "#     # x_noisy = degrade_fn(x)\n",
    "#     x_noisy = degrade_fn(x_fft) + torch.randn_like(x_fft) * betas[i]\n",
    "#     # x_noisy = degrade_fn(x) + torch.randn_like(x) * betas[i]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(torch.concat([x_noisy.real, x_noisy.imag[:,1:-1,:]], dim=1).flatten())\n",
    "#     fig.savefig(f\"noisy_{i+1}.png\")\n",
    "#     plt.close()\n",
    "#     # if i == (T - 1):\n",
    "#     #     print(norm.fit(x_noisy.numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.utils.fourier import dft, idft\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Generate a random time-domain signal\n",
    "N = 1000  # Number of samples\n",
    "\n",
    "# signal = 2 * torch.sin(torch.linspace(0, 10, 1000))\n",
    "# signal = torch.randn(N)\n",
    "# signal = 2 * torch.sin(torch.linspace(0, 10, N))  + torch.randn(N) + 10\n",
    "signal = x.flatten()\n",
    "N = len(signal)\n",
    "print(torch.std(signal, unbiased=False))\n",
    "signal_norm = (signal - torch.mean(signal)) / torch.std(signal, unbiased=False)\n",
    "print(signal_norm[:10])\n",
    "plt.plot(signal)\n",
    "\n",
    "# Compute the DFT of the signal using PyTorch's rfft function with norm='ortho'\n",
    "# x_fft = torch.fft.rfft(signal, norm='ortho')\n",
    "x_fft = dft(signal.reshape(1,-1,1), real_imag=True).flatten()\n",
    "print(torch.std(x_fft, unbiased=False))\n",
    "# plt.plot(x_fft * 2**0.5)\n",
    "\n",
    "\n",
    "# Calculate the mean from the DFT coefficients\n",
    "mean = x_fft[0].real\n",
    "mean_minus = torch.concat([mean.reshape(-1,1), torch.zeros(len(x_fft)-1, 1)]).flatten()\n",
    "\n",
    "# Calculate the variance and standard deviation from the DFT coefficients\n",
    "energy_freq = torch.sum(torch.abs(x_fft[1:])**2) * 2 # Account for orthogonal normalization and one-sided representation\n",
    "adjusted_energy = energy_freq\n",
    "variance = adjusted_energy / (N)\n",
    "std_dev = torch.sqrt(variance)\n",
    "signal_fft_norm = (x_fft - mean_minus) / std_dev\n",
    "# inv_signal_fft_norm = torch.fft.irfft(signal_fft_norm, norm='ortho')\n",
    "inv_signal_fft_norm = idft(signal_fft_norm.reshape(1, -1, 1), real_imag=True).flatten()\n",
    "print(inv_signal_fft_norm[:10])\n",
    "# plt.plot(inv_signal_fft_norm)\n",
    "(inv_signal_fft_norm - signal_norm).max()\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Mean (Time Domain):\", torch.mean(signal).item())\n",
    "# print(\"Mean (Frequency Domain):\", mean.item())\n",
    "# print(\"Standard Deviation (Time Domain):\", torch.std(signal).item())\n",
    "# print(\"Standard Deviation (Frequency Domain):\", std_dev.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from src.schedules.collection import linear_schedule, cosine_schedule\n",
    "from src.utils.filters import MovingAvgFreq, MovingAvgTime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "freq = torch.fft.rfftfreq(x.shape[1])\n",
    "x_freq = torch.fft.rfft(x, dim=1, norm='ortho')\n",
    "kernel_size = 10\n",
    "\n",
    "maf = MovingAvgFreq(kernel_size, freq=freq)\n",
    "x_freq_flt = maf(x_freq)\n",
    "x_freq_flt = torch.fft.irfft(x_freq_flt, dim=1, norm='ortho')[:,kernel_size-1::kernel_size,:]\n",
    "x_time_flt = torch.nn.functional.avg_pool1d(x.permute(0,2,1), kernel_size, kernel_size)\n",
    "plt.plot(x_freq_flt.flatten())\n",
    "plt.plot(x_time_flt.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "from src.utils.fourier import complex2sphere, sphere2complex\n",
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "kernel_size = 10\n",
    "# x = torch.randn(12).reshape(1, -1, 1)\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "mat = MovingAvgTime(kernel_size)\n",
    "x_down_real = mat(x)\n",
    "mat_stride = torch.nn.AvgPool1d(kernel_size, kernel_size)\n",
    "x_down_real_stride = mat_stride(x.permute(0, 2, 1))\n",
    "\n",
    "rec = torch.nn.functional.interpolate(\n",
    "    x_down_real.reshape(1, 1, -1), size=x.shape[1] - kernel_size + 1, mode='nearest-exact'\n",
    ")\n",
    "real = x_down_real_stride.flatten()\n",
    "plt.plot(rec[0,0,::kernel_size])\n",
    "plt.plot(real.flatten())\n",
    "((rec[0,0,::kernel_size] - real.flatten())**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(12).reshape(1, -1, 1).float()\n",
    "avg = torch.nn.AvgPool1d(3,3)\n",
    "a_avg = avg(a.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "mean = torch.mean(a, dim=1, keepdim=True)\n",
    "stdev = torch.sqrt(torch.var(a, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "a_norm = (a - mean) / stdev\n",
    "a_norm_avg = avg(a_norm.permute(0,2,1)).permute(0,2,1)\n",
    "torch.allclose(a_norm_avg*stdev + mean, a_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.arange(16).float()\n",
    "\n",
    "a_fft_norm = torch.fft.rfft(a, norm='ortho')\n",
    "\n",
    "k1 = 12\n",
    "k2 = -2\n",
    "\n",
    "print(a_fft_norm)\n",
    "b = k1 * a + k2\n",
    "print(b)\n",
    "b_fft = a_fft_norm.clone() \n",
    "b_fft = b_fft * k1\n",
    "b_fft[0] += k2 * len(a) ** 0.5 \n",
    "print(b_fft)\n",
    "# print(b_fft)\n",
    "# print(b)\n",
    "print(torch.fft.irfft(b_fft, norm='ortho'))\n",
    "# torch.allclose(4*a, torch.fft.irfft(a_fft * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils.schedule import linear_schedule, cosine_schedule\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_,_,_,a = linear_schedule(1e-4, 1e-2, 288)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ks = 100\n",
    "# a = torch.sin(torch.linspace(0, torch.pi * 2, 1000)).float()\n",
    "# a = a + torch.randn_like(a) * 0.1\n",
    "a = torch.arange(100000).float()\n",
    "a_std, a_mean = torch.std_mean(a)\n",
    "print(a_std, a_mean)\n",
    "a = torch.nn.functional.avg_pool1d(a.reshape(1, 1, -1), ks, 1).flatten()\n",
    "a_std, a_mean = torch.std_mean(a)\n",
    "print(a_std, a_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 1000\n",
    "a = torch.sin(torch.linspace(0, 100, N)) + torch.exp(torch.linspace(0, 100, N) / 50)\n",
    "\n",
    "plt.plot(a)\n",
    "a_fft = torch.fft.rfft(a)\n",
    "print(a_fft[0])\n",
    "# plt.plot(a_fft.real)\n",
    "# plt.plot(a_fft.imag)\n",
    "noise = torch.randn(N)\n",
    "a = a + noise\n",
    "plt.plot(a)\n",
    "a_fft = torch.fft.rfft(a)\n",
    "print(a_fft[0])\n",
    "print(torch.fft.rfft(noise)[0])\n",
    "# plt.plot(a_fft.real)\n",
    "# plt.plot(a_fft.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_freq = pd.read_csv('../assets/MADFreq_fast_dtm.csv', index_col=0)\n",
    "# df_time = pd.read_csv('../assets/MADTime_fast_dtm_old.csv', index_col=0)\n",
    "df_time = pd.read_csv('../assets/MADTime_fast_dtm_20240621013629.csv', index_col=0)\n",
    "df = pd.concat([df_freq, df_time])\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df[df['method'].str.contains('MLPBackbone_freq_norm_True_diff_True')]\n",
    "df[df['granularity']==1].sort_values('RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../assets/fast_dtm.csv', index_col=0)\n",
    "df[df['granularity']==1].sort_values('RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.schedule import linear_schedule, cosine_schedule\n",
    "\n",
    "var_schedule = torch.load(\"/home/user/data/FrequencyDiffusion/savings/mfred/std_schedule.pt\")\n",
    "# print(var_schedule)\n",
    "var_schedule = torch.sqrt(1 - var_schedule**2)\n",
    "# # torch.save(torch.sqrt(1 - var_schedule**2), \"/home/user/data/FrequencyDiffusion/savings/empirical_schedule.pt\")\n",
    "# betas = linear_schedule(1e-4, 2e-2, len(var_schedule))[-1]\n",
    "plt.plot(var_schedule, label=\"empirical\")\n",
    "\n",
    "var_schedule = 1 / torch.arange(2, 289)\n",
    "var_schedule = torch.sqrt(1 - var_schedule)\n",
    "plt.plot(var_schedule, label='approx')\n",
    "# torch.save(betas, \"/home/user/data/FrequencyDiffusion/savings/ddpm_schedule.pt\")\n",
    "# betas = cosine_schedule(len(var_schedule))[-1]\n",
    "# plt.plot(betas, label=\"cosine\")\n",
    "# # torch.save(betas, \"/home/user/data/FrequencyDiffusion/savings/cosine_schedule.pt\")\n",
    "\n",
    "# # plt.plot(var_schedule, label='std_ratio')\n",
    "# # plt.plot(1 - var_schedule, label=\"1-sr\")\n",
    "# # plt.plot(torch.sqrt(1 - var_schedule), label=\"$\\sqrt{1-sr}$\")\n",
    "# plt.plot(var_schedule, label=\"$\\sqrt{1-sr^2}$\")\n",
    "# # plt.plot(betas, label=\"cosine\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('/home/user/data/FrequencyDiffusion/savings/mfred/benchmarks/bench_metrics.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "print(results)\n",
    "keys = results[0].keys()\n",
    "all_results = {k:[] for k in keys}\n",
    "for r in results:\n",
    "    for k in keys:\n",
    "        all_results[k].append(r[k])\n",
    "for k in keys:\n",
    "    metrics = all_results[k]\n",
    "    metrics = np.array(metrics)\n",
    "    print(k)\n",
    "    print(metrics.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv', index_col=0, parse_dates=True)\n",
    "df = df.drop(columns=['weekday', 'hour'])\n",
    "df.to_csv('/home/user/data/FrequencyDiffusion/dataset/MFRED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.datamodule.data_loader import Dataset_Custom, Dataset_ETT_hour\n",
    "\n",
    "dl = Dataset_ETT_hour(\n",
    "    None,\n",
    "    root_path=\"/home/user/data/THU-timeseries/ETT-small/\",\n",
    "    # root_path=\"/home/user/data/FrequencyDiffusion/dataset/\",\n",
    "    data_path=\"ETTh1.csv\",\n",
    "    # data_path=\"MFRED.csv\",\n",
    "    flag=\"test\",\n",
    "    size=[96, 48, 96],\n",
    "    freq=\"h\", scale=False\n",
    ")\n",
    "dl = DataLoader(dl, batch_size=128, shuffle=False, drop_last=True)\n",
    "for batch in dl:\n",
    "    seq_x, seq_y, seq_x_mark, seq_y_mark = batch\n",
    "    print(seq_x.shape)\n",
    "    print(seq_x[0, :10])\n",
    "    print(seq_y[0, -96:])\n",
    "    print(seq_x_mark[0,:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodule.dataset import mfred\n",
    "import yaml\n",
    "\n",
    "data_config = yaml.safe_load(open('../configs/mfred.yaml'))\n",
    "data_config['scale'] = False\n",
    "train_dl, val_dl, test_dl, y_scaler = mfred(data_config)\n",
    "for batch in test_dl:\n",
    "    seq_x = batch['observed_data']\n",
    "    seq_y = batch['future_data']\n",
    "    print(seq_x[0, :10])\n",
    "    print(seq_y[0, :10])\n",
    "    # print(seq_x_mark)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: ['constant', 'exchange_rate', 'solar-energy', 'electricity', 'traffic', 'exchange_rate_nips', 'electricity_nips', 'traffic_nips', 'solar_nips', 'wiki2000_nips', 'wiki-rolling_nips', 'taxi_30min', 'kaggle_web_traffic_with_missing', 'kaggle_web_traffic_without_missing', 'kaggle_web_traffic_weekly', 'm1_yearly', 'm1_quarterly', 'm1_monthly', 'nn5_daily_with_missing', 'nn5_daily_without_missing', 'nn5_weekly', 'tourism_monthly', 'tourism_quarterly', 'tourism_yearly', 'cif_2016', 'london_smart_meters_without_missing', 'wind_farms_without_missing', 'car_parts_without_missing', 'dominick', 'fred_md', 'pedestrian_counts', 'hospital', 'covid_deaths', 'kdd_cup_2018_without_missing', 'weather', 'm3_monthly', 'm3_quarterly', 'm3_yearly', 'm3_other', 'm4_hourly', 'm4_daily', 'm4_weekly', 'm4_monthly', 'm4_quarterly', 'm4_yearly', 'm5', 'uber_tlc_daily', 'uber_tlc_hourly', 'airpassengers', 'australian_electricity_demand', 'electricity_hourly', 'electricity_weekly', 'rideshare_without_missing', 'saugeenday', 'solar_10_minutes', 'solar_weekly', 'sunspot_without_missing', 'temperature_rain_without_missing', 'vehicle_trips_without_missing', 'ercot', 'ett_small_15min', 'ett_small_1h']\n",
      "2590\n",
      "370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'370'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.loader import TrainDataLoader\n",
    "from gluonts.dataset.split import split\n",
    "import pandas as pd\n",
    "from gluonts.torch.batchify import batchify, stack\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "import numpy as np\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "print(f\"Available datasets: {dataset_names}\")\n",
    "dataset = get_dataset(\"electricity_nips\")\n",
    "print(len(dataset.test))\n",
    "print(len(dataset.train))\n",
    "dataset.metadata.feat_static_cat[0].cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ts.shape: (240, 1)\n",
      "                       target\n",
      "2021-01-01 00:00:00 -0.636736\n",
      "2021-01-01 01:00:00 -0.660553\n",
      "2021-01-01 02:00:00 -0.783723\n",
      "2021-01-01 03:00:00 -0.969599\n",
      "2021-01-01 04:00:00 -1.018893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_single_ts(date_range, item_id=None) -> pd.DataFrame:\n",
    "    \"\"\"create sum of `n_f` sin/cos curves with random scale and phase.\"\"\"\n",
    "    n_f = 2\n",
    "    period = np.array([24 / (i + 1) for i in range(n_f)]).reshape(1, n_f)\n",
    "    scale = np.random.normal(1, 0.3, size=(1, n_f))\n",
    "    phase = 2 * np.pi * np.random.uniform(size=(1, n_f))\n",
    "    periodic_f = lambda x: scale * np.sin(np.pi * x / period + phase)\n",
    "\n",
    "    t = np.arange(0, len(date_range)).reshape(-1, 1)\n",
    "    target = periodic_f(t).sum(axis=1) + np.random.normal(0, 0.1, size=len(t))\n",
    "    ts = pd.DataFrame({\"target\": target}, index=date_range)\n",
    "    if item_id is not None:\n",
    "        ts[\"item_id\"] = item_id\n",
    "    return ts\n",
    "\n",
    "prediction_length, freq = 24, \"1H\"\n",
    "T = 10 * prediction_length\n",
    "date_range = pd.date_range(\"2021-01-01\", periods=T, freq=freq)\n",
    "ts = generate_single_ts(date_range)\n",
    "\n",
    "print(\"ts.shape:\", ts.shape)\n",
    "print(ts.head())\n",
    "ts.loc[:, \"target\"].plot(figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.torch import DeepAREstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "\n",
    "\n",
    "def train_and_predict(dataset, estimator):\n",
    "    predictor = estimator.train(dataset)\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=dataset, predictor=predictor\n",
    "    )\n",
    "    evaluator = Evaluator(quantiles=(np.arange(20) / 20.0)[1:], num_workers=0)\n",
    "    agg_metrics, item_metrics = evaluator(ts_it, forecast_it, num_series=len(dataset))\n",
    "    return agg_metrics[\"MSE\"]\n",
    "\n",
    "\n",
    "estimator = DeepAREstimator(\n",
    "    freq=freq, prediction_length=prediction_length, trainer_kwargs={'max_steps':3,'accelerator':'cpu',})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 27.6 K | [[1, 1], [1, 1], [1, 744, 5], [1, 744], [1, 744], [1, 24, 5]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "27.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 K    Total params\n",
      "0.111     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 24.74it/s, v_num=24, train_loss=1.870]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.86585 (best 1.86585), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_24/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 23.55it/s, v_num=24, train_loss=1.870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.8235253185226856"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset\n",
    "\n",
    "ds = PandasDataset(ts, target=\"target\", freq=freq)\n",
    "train_and_predict(ds, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 27.6 K | [[1, 1], [1, 1], [1, 744, 5], [1, 744], [1, 744], [1, 24, 5]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "27.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 K    Total params\n",
      "0.111     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 22.00it/s, v_num=25, train_loss=1.600]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.60474 (best 1.60474), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_25/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 21.05it/s, v_num=25, train_loss=1.600]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|| 10/10 [00:00<00:00, 27.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8586620670121011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "N = 10\n",
    "multiple_ts = [generate_single_ts(date_range) for i in range(N)]\n",
    "\n",
    "ds = PandasDataset(multiple_ts, target=\"target\", freq=freq)\n",
    "train_and_predict(ds, estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 27.6 K | [[1, 1], [1, 1], [1, 744, 5], [1, 744], [1, 744], [1, 24, 5]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "27.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.6 K    Total params\n",
      "0.111     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 0/? [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 27.01it/s, v_num=26, train_loss=1.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.54151 (best 1.54151), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_26/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 25.76it/s, v_num=26, train_loss=1.540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|| 10/10 [00:00<00:00, 30.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8182805381173184"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_in_long_format = pd.concat(\n",
    "    [generate_single_ts(date_range, item_id=i) for i in range(N)]\n",
    ")\n",
    "# ts_in_long_format\n",
    "\n",
    "# # Note we need an item_id column now and provide its name to the constructor.\n",
    "# # Otherwise, there is no way to distinguish different time series.\n",
    "ds = PandasDataset.from_long_dataframe(\n",
    "    ts_in_long_format, item_id=\"item_id\", target=\"target\", freq=freq\n",
    ")\n",
    "train_and_predict(ds, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dynamic_real_1</th>\n",
       "      <th>dynamic_real_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-01 00:00:00</th>\n",
       "      <td>0.367557</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219205</td>\n",
       "      <td>-1.006652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 01:00:00</th>\n",
       "      <td>0.404260</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.414811</td>\n",
       "      <td>-1.392489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 02:00:00</th>\n",
       "      <td>0.423891</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027503</td>\n",
       "      <td>-0.429073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 03:00:00</th>\n",
       "      <td>0.404481</td>\n",
       "      <td>0</td>\n",
       "      <td>1.374566</td>\n",
       "      <td>0.539181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 04:00:00</th>\n",
       "      <td>0.364274</td>\n",
       "      <td>0</td>\n",
       "      <td>0.697070</td>\n",
       "      <td>0.961918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10 19:00:00</th>\n",
       "      <td>-0.343222</td>\n",
       "      <td>0</td>\n",
       "      <td>1.313939</td>\n",
       "      <td>0.575888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10 20:00:00</th>\n",
       "      <td>-0.022693</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.391024</td>\n",
       "      <td>-0.577072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10 21:00:00</th>\n",
       "      <td>0.347139</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.506644</td>\n",
       "      <td>1.074423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10 22:00:00</th>\n",
       "      <td>0.397295</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569750</td>\n",
       "      <td>0.625289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-10 23:00:00</th>\n",
       "      <td>0.411911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.784943</td>\n",
       "      <td>0.481387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       target  item_id  dynamic_real_1  dynamic_real_2\n",
       "2021-01-01 00:00:00  0.367557        0        0.219205       -1.006652\n",
       "2021-01-01 01:00:00  0.404260        0       -1.414811       -1.392489\n",
       "2021-01-01 02:00:00  0.423891        0       -0.027503       -0.429073\n",
       "2021-01-01 03:00:00  0.404481        0        1.374566        0.539181\n",
       "2021-01-01 04:00:00  0.364274        0        0.697070        0.961918\n",
       "...                       ...      ...             ...             ...\n",
       "2021-01-10 19:00:00 -0.343222        0        1.313939        0.575888\n",
       "2021-01-10 20:00:00 -0.022693        0       -0.391024       -0.577072\n",
       "2021-01-10 21:00:00  0.347139        0       -1.506644        1.074423\n",
       "2021-01-10 22:00:00  0.397295        0        0.569750        0.625289\n",
       "2021-01-10 23:00:00  0.411911        0        0.784943        0.481387\n",
       "\n",
       "[240 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_single_ts_with_features(date_range, item_id) -> pd.DataFrame:\n",
    "    ts = generate_single_ts(date_range, item_id)\n",
    "    T = ts.shape[0]\n",
    "    # static features are constant for each series\n",
    "    ts[\"dynamic_real_1\"] = np.random.normal(size=T)\n",
    "    ts[\"dynamic_real_2\"] = np.random.normal(size=T)\n",
    "    # ... we can have as many static or dynamic features as we like\n",
    "    return ts\n",
    "\n",
    "\n",
    "ts = generate_single_ts_with_features(date_range, item_id=0)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_with_features = DeepAREstimator(\n",
    "    freq=ds.freq,\n",
    "    prediction_length=prediction_length,\n",
    "    num_feat_dynamic_real=2,\n",
    "    num_feat_static_cat=1,\n",
    "    num_feat_static_real=1,\n",
    "    cardinality=[\n",
    "        3,\n",
    "    ],\n",
    "    trainer_kwargs={'max_steps':3,'accelerator':'cpu',}\n",
    "    # trainer=Trainer(epochs=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>104.136626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>94.284978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>100.128481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "      <td>77.262578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>91.437047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>red</td>\n",
       "      <td>82.157661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>red</td>\n",
       "      <td>127.284947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>green</td>\n",
       "      <td>60.082463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>red</td>\n",
       "      <td>95.738680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>green</td>\n",
       "      <td>83.861204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color      height\n",
       "0   blue  104.136626\n",
       "1   blue   94.284978\n",
       "2   blue  100.128481\n",
       "3  green   77.262578\n",
       "4   blue   91.437047\n",
       "5    red   82.157661\n",
       "6    red  127.284947\n",
       "7  green   60.082463\n",
       "8    red   95.738680\n",
       "9  green   83.861204"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_ts = {\n",
    "    i: generate_single_ts_with_features(date_range, item_id=i) for i in range(N)\n",
    "}\n",
    "static_features = pd.DataFrame(\n",
    "    {\n",
    "        \"color\": pd.Categorical(np.random.choice([\"red\", \"green\", \"blue\"], size=N)),\n",
    "        \"height\": np.random.normal(loc=100, scale=15, size=N),\n",
    "    },\n",
    "    index=list(multiple_ts.keys()),\n",
    ")\n",
    "multiple_ts_long = pd.concat(multiple_ts.values())\n",
    "\n",
    "multiple_ts_dataset = PandasDataset(\n",
    "    multiple_ts,\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "# for long-dataset we use a different constructor and need a `item_id` column\n",
    "multiple_ts_long_dataset = PandasDataset.from_long_dataframe(\n",
    "    multiple_ts_long,\n",
    "    item_id=\"item_id\",\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 28.1 K | [[1, 1], [1, 1], [1, 744, 7], [1, 744], [1, 744], [1, 24, 7]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "28.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.1 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 19.95it/s, v_num=27, train_loss=1.620]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.61942 (best 1.61942), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_27/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 19.27it/s, v_num=27, train_loss=1.620]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|| 10/10 [00:00<00:00, 42.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.435222067058141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(multiple_ts_dataset, estimator_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 28.1 K | [[1, 1], [1, 1], [1, 744, 7], [1, 744], [1, 744], [1, 24, 7]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "28.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.1 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 18.07it/s, v_num=28, train_loss=1.780]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.78289 (best 1.78289), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_28/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 17.52it/s, v_num=28, train_loss=1.780]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|| 10/10 [00:00<00:00, 30.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3706744461259177"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_predict(multiple_ts_long_dataset, estimator_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = PandasDataset(\n",
    "    {item_id: df[:-3*prediction_length] for item_id, df in multiple_ts.items()},\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "\n",
    "test = PandasDataset(\n",
    "    multiple_ts,\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/home/user/anaconda3/envs/freqdiff310/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                      | Out sizes   \n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 28.1 K | [[1, 1], [1, 1], [1, 744, 7], [1, 744], [1, 744], [1, 24, 7]] | [1, 100, 24]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "28.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.1 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 17.72it/s, v_num=29, train_loss=1.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'train_loss' reached 1.67355 (best 1.67355), saving model to '/home/user/workspaces/FrequencyDiffusion/notebooks/lightning_logs/version_29/checkpoints/epoch=0-step=3.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_steps=3` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 3/? [00:00<00:00, 17.16it/s, v_num=29, train_loss=1.670]\n"
     ]
    }
   ],
   "source": [
    "predictor = estimator_with_features.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 490it [00:03, 150.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.split import split\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.util import period_index, to_pandas\n",
    "\n",
    "\n",
    "def _to_dataframe(input_label) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turn a pair of consecutive (in time) data entries into a dataframe.\n",
    "    \"\"\"\n",
    "    start = input_label[0][FieldName.START]\n",
    "    targets = [entry[FieldName.TARGET] for entry in input_label]\n",
    "    full_target = np.concatenate(targets, axis=-1)\n",
    "    index = period_index({FieldName.START: start, FieldName.TARGET: full_target})\n",
    "    return pd.DataFrame(full_target.transpose(), index=index)\n",
    "\n",
    "\n",
    "window_length = predictor.prediction_length + predictor.lead_time\n",
    "# print(predictor.lead_time)\n",
    "training_data, test_template = split(test, offset=-3 * window_length)\n",
    "test_data = test_template.generate_instances(window_length, windows=2 * window_length + 1, distance=1, max_history=window_length)\n",
    "forecast_it, ts_it = (\n",
    "    predictor.predict(test_data.input, num_samples=100),\n",
    "    map(_to_dataframe, test_data),\n",
    ")\n",
    "forecasts_pytorch = list(forecast_it)\n",
    "tss_pytorch = list(ts_it)\n",
    "\n",
    "evaluator = Evaluator(quantiles=(np.arange(20) / 20.0)[1:], num_workers=0)\n",
    "agg_metrics, item_metrics = evaluator(tss_pytorch, forecasts_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>forecast_start</th>\n",
       "      <th>MSE</th>\n",
       "      <th>abs_error</th>\n",
       "      <th>abs_target_sum</th>\n",
       "      <th>abs_target_mean</th>\n",
       "      <th>seasonal_error</th>\n",
       "      <th>MASE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>...</th>\n",
       "      <th>QuantileLoss[0.75]</th>\n",
       "      <th>Coverage[0.75]</th>\n",
       "      <th>QuantileLoss[0.8]</th>\n",
       "      <th>Coverage[0.8]</th>\n",
       "      <th>QuantileLoss[0.85]</th>\n",
       "      <th>Coverage[0.85]</th>\n",
       "      <th>QuantileLoss[0.9]</th>\n",
       "      <th>Coverage[0.9]</th>\n",
       "      <th>QuantileLoss[0.95]</th>\n",
       "      <th>Coverage[0.95]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.724931</td>\n",
       "      <td>16.527919</td>\n",
       "      <td>17.553722</td>\n",
       "      <td>0.731405</td>\n",
       "      <td>1.013406</td>\n",
       "      <td>0.679553</td>\n",
       "      <td>0.953573</td>\n",
       "      <td>1.559192</td>\n",
       "      <td>...</td>\n",
       "      <td>12.307343</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>10.941409</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>9.535338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.724808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.157125</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.679262</td>\n",
       "      <td>15.986018</td>\n",
       "      <td>17.736067</td>\n",
       "      <td>0.739003</td>\n",
       "      <td>1.007922</td>\n",
       "      <td>0.660849</td>\n",
       "      <td>0.875999</td>\n",
       "      <td>1.515089</td>\n",
       "      <td>...</td>\n",
       "      <td>12.482090</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>11.089779</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>9.724944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.210302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.471453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>0.676397</td>\n",
       "      <td>17.216761</td>\n",
       "      <td>17.721720</td>\n",
       "      <td>0.738405</td>\n",
       "      <td>1.001412</td>\n",
       "      <td>0.716353</td>\n",
       "      <td>1.037261</td>\n",
       "      <td>1.635890</td>\n",
       "      <td>...</td>\n",
       "      <td>12.595585</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>11.363930</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>9.583450</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.658261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.216567</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.705593</td>\n",
       "      <td>17.047312</td>\n",
       "      <td>17.546026</td>\n",
       "      <td>0.731084</td>\n",
       "      <td>0.995559</td>\n",
       "      <td>0.713474</td>\n",
       "      <td>1.033324</td>\n",
       "      <td>1.681472</td>\n",
       "      <td>...</td>\n",
       "      <td>12.355034</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>11.215099</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>9.766723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.985700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.461416</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.656335</td>\n",
       "      <td>16.209379</td>\n",
       "      <td>17.244549</td>\n",
       "      <td>0.718523</td>\n",
       "      <td>0.989259</td>\n",
       "      <td>0.682724</td>\n",
       "      <td>0.886428</td>\n",
       "      <td>1.552667</td>\n",
       "      <td>...</td>\n",
       "      <td>12.311253</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>10.983494</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>9.394270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.721919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.289974</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.537962</td>\n",
       "      <td>15.150515</td>\n",
       "      <td>15.388713</td>\n",
       "      <td>0.641196</td>\n",
       "      <td>1.252697</td>\n",
       "      <td>0.503930</td>\n",
       "      <td>1.556807</td>\n",
       "      <td>1.659295</td>\n",
       "      <td>...</td>\n",
       "      <td>13.804217</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.816130</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.172144</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.024492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.866569</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.462824</td>\n",
       "      <td>12.875581</td>\n",
       "      <td>15.018085</td>\n",
       "      <td>0.625754</td>\n",
       "      <td>1.247141</td>\n",
       "      <td>0.430170</td>\n",
       "      <td>1.403961</td>\n",
       "      <td>1.398622</td>\n",
       "      <td>...</td>\n",
       "      <td>13.563750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.567133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.219251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.162633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.864446</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>0.475368</td>\n",
       "      <td>13.963230</td>\n",
       "      <td>14.561311</td>\n",
       "      <td>0.606721</td>\n",
       "      <td>1.241479</td>\n",
       "      <td>0.468636</td>\n",
       "      <td>1.376275</td>\n",
       "      <td>1.588915</td>\n",
       "      <td>...</td>\n",
       "      <td>13.682346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.030948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.471467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.122589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.963617</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.352052</td>\n",
       "      <td>11.998916</td>\n",
       "      <td>13.631264</td>\n",
       "      <td>0.567969</td>\n",
       "      <td>1.239399</td>\n",
       "      <td>0.403385</td>\n",
       "      <td>1.464127</td>\n",
       "      <td>1.507794</td>\n",
       "      <td>...</td>\n",
       "      <td>13.211938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.224991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.976226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.042314</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.156625</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.397126</td>\n",
       "      <td>11.820977</td>\n",
       "      <td>12.962066</td>\n",
       "      <td>0.540086</td>\n",
       "      <td>1.236414</td>\n",
       "      <td>0.398362</td>\n",
       "      <td>1.776623</td>\n",
       "      <td>1.362131</td>\n",
       "      <td>...</td>\n",
       "      <td>13.141296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.417281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.365704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.253060</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.211123</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>1.513732</td>\n",
       "      <td>20.104020</td>\n",
       "      <td>18.804755</td>\n",
       "      <td>0.783531</td>\n",
       "      <td>1.911116</td>\n",
       "      <td>0.438313</td>\n",
       "      <td>1.470422</td>\n",
       "      <td>1.526055</td>\n",
       "      <td>...</td>\n",
       "      <td>19.916450</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>18.190182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>15.076023</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>10.590061</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>5.047673</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>1.204729</td>\n",
       "      <td>17.777647</td>\n",
       "      <td>16.737476</td>\n",
       "      <td>0.697395</td>\n",
       "      <td>1.913716</td>\n",
       "      <td>0.387067</td>\n",
       "      <td>1.517775</td>\n",
       "      <td>1.473789</td>\n",
       "      <td>...</td>\n",
       "      <td>17.683054</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>16.488584</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.904601</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9.538211</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4.908834</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>1.127575</td>\n",
       "      <td>16.172207</td>\n",
       "      <td>14.765979</td>\n",
       "      <td>0.615249</td>\n",
       "      <td>1.918921</td>\n",
       "      <td>0.351157</td>\n",
       "      <td>2.304843</td>\n",
       "      <td>1.440132</td>\n",
       "      <td>...</td>\n",
       "      <td>16.480502</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>15.017699</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>12.774426</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>9.447886</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>5.502651</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.812977</td>\n",
       "      <td>15.441484</td>\n",
       "      <td>13.029940</td>\n",
       "      <td>0.542914</td>\n",
       "      <td>1.925023</td>\n",
       "      <td>0.334227</td>\n",
       "      <td>2.325003</td>\n",
       "      <td>1.627377</td>\n",
       "      <td>...</td>\n",
       "      <td>15.109884</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.832673</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>11.446580</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9.027000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>6.139118</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.893592</td>\n",
       "      <td>13.453444</td>\n",
       "      <td>11.605375</td>\n",
       "      <td>0.483557</td>\n",
       "      <td>1.932735</td>\n",
       "      <td>0.290035</td>\n",
       "      <td>2.122177</td>\n",
       "      <td>1.516446</td>\n",
       "      <td>...</td>\n",
       "      <td>14.454401</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.264270</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>11.985966</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>10.143289</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>6.653918</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.612102</td>\n",
       "      <td>16.461106</td>\n",
       "      <td>16.563722</td>\n",
       "      <td>0.690155</td>\n",
       "      <td>1.011805</td>\n",
       "      <td>0.677877</td>\n",
       "      <td>1.263071</td>\n",
       "      <td>1.857187</td>\n",
       "      <td>...</td>\n",
       "      <td>11.922303</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>10.269991</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8.339809</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.896901</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>2.980712</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.556890</td>\n",
       "      <td>15.332004</td>\n",
       "      <td>15.654504</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>1.009808</td>\n",
       "      <td>0.632628</td>\n",
       "      <td>1.282832</td>\n",
       "      <td>1.826230</td>\n",
       "      <td>...</td>\n",
       "      <td>10.635867</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>9.122565</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>7.706726</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>5.936623</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3.392868</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>0.492331</td>\n",
       "      <td>14.718576</td>\n",
       "      <td>14.946640</td>\n",
       "      <td>0.622777</td>\n",
       "      <td>1.008438</td>\n",
       "      <td>0.608142</td>\n",
       "      <td>1.015443</td>\n",
       "      <td>1.776577</td>\n",
       "      <td>...</td>\n",
       "      <td>9.938292</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.449329</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>7.078583</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>5.397418</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3.277453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.502849</td>\n",
       "      <td>14.125379</td>\n",
       "      <td>14.444540</td>\n",
       "      <td>0.601856</td>\n",
       "      <td>1.005121</td>\n",
       "      <td>0.585559</td>\n",
       "      <td>1.259745</td>\n",
       "      <td>1.769864</td>\n",
       "      <td>...</td>\n",
       "      <td>9.589591</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.334304</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>7.071426</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.686759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.664867</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.518965</td>\n",
       "      <td>13.754369</td>\n",
       "      <td>14.030731</td>\n",
       "      <td>0.584614</td>\n",
       "      <td>1.000257</td>\n",
       "      <td>0.572952</td>\n",
       "      <td>1.209008</td>\n",
       "      <td>1.682247</td>\n",
       "      <td>...</td>\n",
       "      <td>9.425490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.493040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.436285</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.828531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.729641</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>1.778524</td>\n",
       "      <td>26.197623</td>\n",
       "      <td>27.387238</td>\n",
       "      <td>1.141135</td>\n",
       "      <td>1.695755</td>\n",
       "      <td>0.643706</td>\n",
       "      <td>1.071539</td>\n",
       "      <td>1.647300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.005885</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>14.195393</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>11.090756</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>8.948596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.918934</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>2.238014</td>\n",
       "      <td>28.994148</td>\n",
       "      <td>29.581335</td>\n",
       "      <td>1.232556</td>\n",
       "      <td>1.701111</td>\n",
       "      <td>0.710177</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>1.714388</td>\n",
       "      <td>...</td>\n",
       "      <td>18.219790</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>15.287306</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>12.071813</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>9.892691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.679425</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>2.474811</td>\n",
       "      <td>31.438668</td>\n",
       "      <td>31.547534</td>\n",
       "      <td>1.314481</td>\n",
       "      <td>1.703338</td>\n",
       "      <td>0.769046</td>\n",
       "      <td>1.149849</td>\n",
       "      <td>1.789413</td>\n",
       "      <td>...</td>\n",
       "      <td>19.674153</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>16.183878</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>12.044741</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9.431882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.491683</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>2.757058</td>\n",
       "      <td>33.267362</td>\n",
       "      <td>33.230784</td>\n",
       "      <td>1.384616</td>\n",
       "      <td>1.701690</td>\n",
       "      <td>0.814567</td>\n",
       "      <td>1.159626</td>\n",
       "      <td>1.829883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.385168</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>18.810923</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>14.973244</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.175970</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>5.922300</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>2.669730</td>\n",
       "      <td>34.835099</td>\n",
       "      <td>34.643483</td>\n",
       "      <td>1.443478</td>\n",
       "      <td>1.701292</td>\n",
       "      <td>0.853153</td>\n",
       "      <td>1.054404</td>\n",
       "      <td>1.812708</td>\n",
       "      <td>...</td>\n",
       "      <td>22.946857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>18.681091</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>14.325852</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>9.594576</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>5.699961</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.806669</td>\n",
       "      <td>14.608191</td>\n",
       "      <td>12.365429</td>\n",
       "      <td>0.515226</td>\n",
       "      <td>1.903879</td>\n",
       "      <td>0.319702</td>\n",
       "      <td>2.080287</td>\n",
       "      <td>1.569188</td>\n",
       "      <td>...</td>\n",
       "      <td>14.350750</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.293393</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>10.950468</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>8.441165</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>5.907164</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.873122</td>\n",
       "      <td>13.879354</td>\n",
       "      <td>13.634782</td>\n",
       "      <td>0.568116</td>\n",
       "      <td>1.910358</td>\n",
       "      <td>0.302721</td>\n",
       "      <td>4.288773</td>\n",
       "      <td>1.260086</td>\n",
       "      <td>...</td>\n",
       "      <td>14.535286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.726700</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>12.165871</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>9.516813</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>5.132470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>1.178565</td>\n",
       "      <td>17.022328</td>\n",
       "      <td>15.523383</td>\n",
       "      <td>0.646808</td>\n",
       "      <td>1.913900</td>\n",
       "      <td>0.370586</td>\n",
       "      <td>2.601370</td>\n",
       "      <td>1.466357</td>\n",
       "      <td>...</td>\n",
       "      <td>17.570472</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>15.777624</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>13.811710</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>8.778838</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.439254</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>1.397242</td>\n",
       "      <td>18.930352</td>\n",
       "      <td>17.501548</td>\n",
       "      <td>0.729231</td>\n",
       "      <td>1.917468</td>\n",
       "      <td>0.411357</td>\n",
       "      <td>1.413722</td>\n",
       "      <td>1.585310</td>\n",
       "      <td>...</td>\n",
       "      <td>19.295114</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>18.475412</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>16.460173</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.090885</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>6.456314</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>1.522453</td>\n",
       "      <td>21.259089</td>\n",
       "      <td>19.578294</td>\n",
       "      <td>0.815762</td>\n",
       "      <td>1.920130</td>\n",
       "      <td>0.461321</td>\n",
       "      <td>1.204354</td>\n",
       "      <td>1.651932</td>\n",
       "      <td>...</td>\n",
       "      <td>22.173845</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>20.284304</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>17.094936</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>11.670557</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5.921161</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.430358</td>\n",
       "      <td>13.533645</td>\n",
       "      <td>16.043830</td>\n",
       "      <td>0.668493</td>\n",
       "      <td>1.624495</td>\n",
       "      <td>0.347124</td>\n",
       "      <td>0.790686</td>\n",
       "      <td>1.375337</td>\n",
       "      <td>...</td>\n",
       "      <td>14.418984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.160827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.498629</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.539135</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.276026</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.457258</td>\n",
       "      <td>13.586045</td>\n",
       "      <td>14.700881</td>\n",
       "      <td>0.612537</td>\n",
       "      <td>1.622685</td>\n",
       "      <td>0.348857</td>\n",
       "      <td>0.883213</td>\n",
       "      <td>1.479540</td>\n",
       "      <td>...</td>\n",
       "      <td>15.269656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.318181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.589408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.585096</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>0.280258</td>\n",
       "      <td>11.669864</td>\n",
       "      <td>13.650718</td>\n",
       "      <td>0.568780</td>\n",
       "      <td>1.622503</td>\n",
       "      <td>0.299688</td>\n",
       "      <td>0.869984</td>\n",
       "      <td>1.452418</td>\n",
       "      <td>...</td>\n",
       "      <td>13.589777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.779006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.752058</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.784720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.498848</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.301847</td>\n",
       "      <td>11.337782</td>\n",
       "      <td>13.104498</td>\n",
       "      <td>0.546021</td>\n",
       "      <td>1.626498</td>\n",
       "      <td>0.290445</td>\n",
       "      <td>0.911764</td>\n",
       "      <td>1.330574</td>\n",
       "      <td>...</td>\n",
       "      <td>13.174960</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>12.465360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.269158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.253498</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.627076</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.320357</td>\n",
       "      <td>12.440404</td>\n",
       "      <td>12.925081</td>\n",
       "      <td>0.538545</td>\n",
       "      <td>1.630459</td>\n",
       "      <td>0.317917</td>\n",
       "      <td>0.996048</td>\n",
       "      <td>1.415932</td>\n",
       "      <td>...</td>\n",
       "      <td>13.192427</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>12.166991</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>10.930972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.028704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.007921</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>3.251507</td>\n",
       "      <td>39.125034</td>\n",
       "      <td>39.408143</td>\n",
       "      <td>1.642006</td>\n",
       "      <td>1.620583</td>\n",
       "      <td>1.005940</td>\n",
       "      <td>0.954806</td>\n",
       "      <td>1.840203</td>\n",
       "      <td>...</td>\n",
       "      <td>38.364751</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>36.686709</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>34.333453</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>30.918752</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>24.395038</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>3.080032</td>\n",
       "      <td>37.542534</td>\n",
       "      <td>37.729875</td>\n",
       "      <td>1.572078</td>\n",
       "      <td>1.626771</td>\n",
       "      <td>0.961581</td>\n",
       "      <td>1.006117</td>\n",
       "      <td>1.902905</td>\n",
       "      <td>...</td>\n",
       "      <td>35.287454</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>33.126264</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>30.384987</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>26.352150</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>18.797424</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>2.893221</td>\n",
       "      <td>35.242191</td>\n",
       "      <td>35.633759</td>\n",
       "      <td>1.484740</td>\n",
       "      <td>1.632600</td>\n",
       "      <td>0.899439</td>\n",
       "      <td>0.973392</td>\n",
       "      <td>1.806499</td>\n",
       "      <td>...</td>\n",
       "      <td>33.160320</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>31.136697</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>28.194545</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>24.462593</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>17.984768</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>2.525768</td>\n",
       "      <td>33.237058</td>\n",
       "      <td>33.183013</td>\n",
       "      <td>1.382626</td>\n",
       "      <td>1.637710</td>\n",
       "      <td>0.845618</td>\n",
       "      <td>0.998729</td>\n",
       "      <td>1.764590</td>\n",
       "      <td>...</td>\n",
       "      <td>29.832046</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>28.171050</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>25.439794</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>20.464149</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>13.415492</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>2.182662</td>\n",
       "      <td>29.691989</td>\n",
       "      <td>30.741752</td>\n",
       "      <td>1.280906</td>\n",
       "      <td>1.644548</td>\n",
       "      <td>0.752283</td>\n",
       "      <td>0.931418</td>\n",
       "      <td>1.648761</td>\n",
       "      <td>...</td>\n",
       "      <td>25.781804</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>23.729855</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>20.389908</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>16.059383</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>8.383249</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.692295</td>\n",
       "      <td>13.253503</td>\n",
       "      <td>13.013843</td>\n",
       "      <td>0.542243</td>\n",
       "      <td>1.352431</td>\n",
       "      <td>0.408323</td>\n",
       "      <td>1.705770</td>\n",
       "      <td>1.512071</td>\n",
       "      <td>...</td>\n",
       "      <td>13.056178</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>11.716176</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>10.266243</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>7.709159</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>4.914773</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.800721</td>\n",
       "      <td>15.078768</td>\n",
       "      <td>14.734986</td>\n",
       "      <td>0.613958</td>\n",
       "      <td>1.354418</td>\n",
       "      <td>0.463876</td>\n",
       "      <td>1.293916</td>\n",
       "      <td>1.580093</td>\n",
       "      <td>...</td>\n",
       "      <td>15.089110</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14.122232</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>12.262899</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>9.679443</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>5.622566</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>1.046720</td>\n",
       "      <td>17.245444</td>\n",
       "      <td>16.359904</td>\n",
       "      <td>0.681663</td>\n",
       "      <td>1.355588</td>\n",
       "      <td>0.530073</td>\n",
       "      <td>1.271075</td>\n",
       "      <td>1.634049</td>\n",
       "      <td>...</td>\n",
       "      <td>18.415771</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>17.380946</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>14.709410</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>11.761991</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.559619</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>1.119647</td>\n",
       "      <td>18.334509</td>\n",
       "      <td>17.890478</td>\n",
       "      <td>0.745437</td>\n",
       "      <td>1.357265</td>\n",
       "      <td>0.562851</td>\n",
       "      <td>1.509230</td>\n",
       "      <td>1.725922</td>\n",
       "      <td>...</td>\n",
       "      <td>19.279011</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>18.152978</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>16.686868</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>12.317728</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.585830</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>8</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>1.162437</td>\n",
       "      <td>19.912748</td>\n",
       "      <td>18.910465</td>\n",
       "      <td>0.787936</td>\n",
       "      <td>1.356550</td>\n",
       "      <td>0.611623</td>\n",
       "      <td>1.678563</td>\n",
       "      <td>1.872719</td>\n",
       "      <td>...</td>\n",
       "      <td>20.421874</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>19.277758</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>17.395408</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>13.599509</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.270064</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-01-08 00:00</td>\n",
       "      <td>0.793306</td>\n",
       "      <td>19.301101</td>\n",
       "      <td>19.163482</td>\n",
       "      <td>0.798478</td>\n",
       "      <td>0.816313</td>\n",
       "      <td>0.985176</td>\n",
       "      <td>1.234011</td>\n",
       "      <td>1.946328</td>\n",
       "      <td>...</td>\n",
       "      <td>16.387427</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>14.841884</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>13.142396</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>10.680427</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>6.319313</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-01-08 01:00</td>\n",
       "      <td>0.730913</td>\n",
       "      <td>18.255734</td>\n",
       "      <td>17.927520</td>\n",
       "      <td>0.746980</td>\n",
       "      <td>0.820633</td>\n",
       "      <td>0.926914</td>\n",
       "      <td>1.100052</td>\n",
       "      <td>1.958750</td>\n",
       "      <td>...</td>\n",
       "      <td>15.694935</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>14.191725</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.990767</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9.135106</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>5.220434</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-01-08 02:00</td>\n",
       "      <td>0.655859</td>\n",
       "      <td>16.976468</td>\n",
       "      <td>16.575669</td>\n",
       "      <td>0.690653</td>\n",
       "      <td>0.824351</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>1.232094</td>\n",
       "      <td>1.924213</td>\n",
       "      <td>...</td>\n",
       "      <td>13.957478</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>12.643265</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>11.318431</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>7.847360</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>3.671637</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-01-08 03:00</td>\n",
       "      <td>0.583505</td>\n",
       "      <td>15.501331</td>\n",
       "      <td>15.223523</td>\n",
       "      <td>0.634313</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>0.780196</td>\n",
       "      <td>1.151535</td>\n",
       "      <td>1.830907</td>\n",
       "      <td>...</td>\n",
       "      <td>13.216395</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>11.871641</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>10.088644</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>7.755532</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>4.138754</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>9</td>\n",
       "      <td>2021-01-08 04:00</td>\n",
       "      <td>0.502494</td>\n",
       "      <td>14.667403</td>\n",
       "      <td>13.975075</td>\n",
       "      <td>0.582295</td>\n",
       "      <td>0.829960</td>\n",
       "      <td>0.736351</td>\n",
       "      <td>1.362682</td>\n",
       "      <td>1.788122</td>\n",
       "      <td>...</td>\n",
       "      <td>11.876936</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>10.246712</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.512246</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>6.157311</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>2.925594</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50 rows  51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id    forecast_start       MSE  abs_error  abs_target_sum  \\\n",
       "0        0  2021-01-08 00:00  0.724931  16.527919       17.553722   \n",
       "1        0  2021-01-08 01:00  0.679262  15.986018       17.736067   \n",
       "2        0  2021-01-08 02:00  0.676397  17.216761       17.721720   \n",
       "3        0  2021-01-08 03:00  0.705593  17.047312       17.546026   \n",
       "4        0  2021-01-08 04:00  0.656335  16.209379       17.244549   \n",
       "5        1  2021-01-08 00:00  0.537962  15.150515       15.388713   \n",
       "6        1  2021-01-08 01:00  0.462824  12.875581       15.018085   \n",
       "7        1  2021-01-08 02:00  0.475368  13.963230       14.561311   \n",
       "8        1  2021-01-08 03:00  0.352052  11.998916       13.631264   \n",
       "9        1  2021-01-08 04:00  0.397126  11.820977       12.962066   \n",
       "10       2  2021-01-08 00:00  1.513732  20.104020       18.804755   \n",
       "11       2  2021-01-08 01:00  1.204729  17.777647       16.737476   \n",
       "12       2  2021-01-08 02:00  1.127575  16.172207       14.765979   \n",
       "13       2  2021-01-08 03:00  0.812977  15.441484       13.029940   \n",
       "14       2  2021-01-08 04:00  0.893592  13.453444       11.605375   \n",
       "15       3  2021-01-08 00:00  0.612102  16.461106       16.563722   \n",
       "16       3  2021-01-08 01:00  0.556890  15.332004       15.654504   \n",
       "17       3  2021-01-08 02:00  0.492331  14.718576       14.946640   \n",
       "18       3  2021-01-08 03:00  0.502849  14.125379       14.444540   \n",
       "19       3  2021-01-08 04:00  0.518965  13.754369       14.030731   \n",
       "20       4  2021-01-08 00:00  1.778524  26.197623       27.387238   \n",
       "21       4  2021-01-08 01:00  2.238014  28.994148       29.581335   \n",
       "22       4  2021-01-08 02:00  2.474811  31.438668       31.547534   \n",
       "23       4  2021-01-08 03:00  2.757058  33.267362       33.230784   \n",
       "24       4  2021-01-08 04:00  2.669730  34.835099       34.643483   \n",
       "25       5  2021-01-08 00:00  0.806669  14.608191       12.365429   \n",
       "26       5  2021-01-08 01:00  0.873122  13.879354       13.634782   \n",
       "27       5  2021-01-08 02:00  1.178565  17.022328       15.523383   \n",
       "28       5  2021-01-08 03:00  1.397242  18.930352       17.501548   \n",
       "29       5  2021-01-08 04:00  1.522453  21.259089       19.578294   \n",
       "30       6  2021-01-08 00:00  0.430358  13.533645       16.043830   \n",
       "31       6  2021-01-08 01:00  0.457258  13.586045       14.700881   \n",
       "32       6  2021-01-08 02:00  0.280258  11.669864       13.650718   \n",
       "33       6  2021-01-08 03:00  0.301847  11.337782       13.104498   \n",
       "34       6  2021-01-08 04:00  0.320357  12.440404       12.925081   \n",
       "35       7  2021-01-08 00:00  3.251507  39.125034       39.408143   \n",
       "36       7  2021-01-08 01:00  3.080032  37.542534       37.729875   \n",
       "37       7  2021-01-08 02:00  2.893221  35.242191       35.633759   \n",
       "38       7  2021-01-08 03:00  2.525768  33.237058       33.183013   \n",
       "39       7  2021-01-08 04:00  2.182662  29.691989       30.741752   \n",
       "40       8  2021-01-08 00:00  0.692295  13.253503       13.013843   \n",
       "41       8  2021-01-08 01:00  0.800721  15.078768       14.734986   \n",
       "42       8  2021-01-08 02:00  1.046720  17.245444       16.359904   \n",
       "43       8  2021-01-08 03:00  1.119647  18.334509       17.890478   \n",
       "44       8  2021-01-08 04:00  1.162437  19.912748       18.910465   \n",
       "45       9  2021-01-08 00:00  0.793306  19.301101       19.163482   \n",
       "46       9  2021-01-08 01:00  0.730913  18.255734       17.927520   \n",
       "47       9  2021-01-08 02:00  0.655859  16.976468       16.575669   \n",
       "48       9  2021-01-08 03:00  0.583505  15.501331       15.223523   \n",
       "49       9  2021-01-08 04:00  0.502494  14.667403       13.975075   \n",
       "\n",
       "    abs_target_mean  seasonal_error      MASE      MAPE     sMAPE  ...  \\\n",
       "0          0.731405        1.013406  0.679553  0.953573  1.559192  ...   \n",
       "1          0.739003        1.007922  0.660849  0.875999  1.515089  ...   \n",
       "2          0.738405        1.001412  0.716353  1.037261  1.635890  ...   \n",
       "3          0.731084        0.995559  0.713474  1.033324  1.681472  ...   \n",
       "4          0.718523        0.989259  0.682724  0.886428  1.552667  ...   \n",
       "5          0.641196        1.252697  0.503930  1.556807  1.659295  ...   \n",
       "6          0.625754        1.247141  0.430170  1.403961  1.398622  ...   \n",
       "7          0.606721        1.241479  0.468636  1.376275  1.588915  ...   \n",
       "8          0.567969        1.239399  0.403385  1.464127  1.507794  ...   \n",
       "9          0.540086        1.236414  0.398362  1.776623  1.362131  ...   \n",
       "10         0.783531        1.911116  0.438313  1.470422  1.526055  ...   \n",
       "11         0.697395        1.913716  0.387067  1.517775  1.473789  ...   \n",
       "12         0.615249        1.918921  0.351157  2.304843  1.440132  ...   \n",
       "13         0.542914        1.925023  0.334227  2.325003  1.627377  ...   \n",
       "14         0.483557        1.932735  0.290035  2.122177  1.516446  ...   \n",
       "15         0.690155        1.011805  0.677877  1.263071  1.857187  ...   \n",
       "16         0.652271        1.009808  0.632628  1.282832  1.826230  ...   \n",
       "17         0.622777        1.008438  0.608142  1.015443  1.776577  ...   \n",
       "18         0.601856        1.005121  0.585559  1.259745  1.769864  ...   \n",
       "19         0.584614        1.000257  0.572952  1.209008  1.682247  ...   \n",
       "20         1.141135        1.695755  0.643706  1.071539  1.647300  ...   \n",
       "21         1.232556        1.701111  0.710177  0.985366  1.714388  ...   \n",
       "22         1.314481        1.703338  0.769046  1.149849  1.789413  ...   \n",
       "23         1.384616        1.701690  0.814567  1.159626  1.829883  ...   \n",
       "24         1.443478        1.701292  0.853153  1.054404  1.812708  ...   \n",
       "25         0.515226        1.903879  0.319702  2.080287  1.569188  ...   \n",
       "26         0.568116        1.910358  0.302721  4.288773  1.260086  ...   \n",
       "27         0.646808        1.913900  0.370586  2.601370  1.466357  ...   \n",
       "28         0.729231        1.917468  0.411357  1.413722  1.585310  ...   \n",
       "29         0.815762        1.920130  0.461321  1.204354  1.651932  ...   \n",
       "30         0.668493        1.624495  0.347124  0.790686  1.375337  ...   \n",
       "31         0.612537        1.622685  0.348857  0.883213  1.479540  ...   \n",
       "32         0.568780        1.622503  0.299688  0.869984  1.452418  ...   \n",
       "33         0.546021        1.626498  0.290445  0.911764  1.330574  ...   \n",
       "34         0.538545        1.630459  0.317917  0.996048  1.415932  ...   \n",
       "35         1.642006        1.620583  1.005940  0.954806  1.840203  ...   \n",
       "36         1.572078        1.626771  0.961581  1.006117  1.902905  ...   \n",
       "37         1.484740        1.632600  0.899439  0.973392  1.806499  ...   \n",
       "38         1.382626        1.637710  0.845618  0.998729  1.764590  ...   \n",
       "39         1.280906        1.644548  0.752283  0.931418  1.648761  ...   \n",
       "40         0.542243        1.352431  0.408323  1.705770  1.512071  ...   \n",
       "41         0.613958        1.354418  0.463876  1.293916  1.580093  ...   \n",
       "42         0.681663        1.355588  0.530073  1.271075  1.634049  ...   \n",
       "43         0.745437        1.357265  0.562851  1.509230  1.725922  ...   \n",
       "44         0.787936        1.356550  0.611623  1.678563  1.872719  ...   \n",
       "45         0.798478        0.816313  0.985176  1.234011  1.946328  ...   \n",
       "46         0.746980        0.820633  0.926914  1.100052  1.958750  ...   \n",
       "47         0.690653        0.824351  0.858072  1.232094  1.924213  ...   \n",
       "48         0.634313        0.827854  0.780196  1.151535  1.830907  ...   \n",
       "49         0.582295        0.829960  0.736351  1.362682  1.788122  ...   \n",
       "\n",
       "    QuantileLoss[0.75]  Coverage[0.75]  QuantileLoss[0.8]  Coverage[0.8]  \\\n",
       "0            12.307343        0.875000          10.941409       0.958333   \n",
       "1            12.482090        0.916667          11.089779       0.958333   \n",
       "2            12.595585        0.875000          11.363930       0.916667   \n",
       "3            12.355034        0.833333          11.215099       0.958333   \n",
       "4            12.311253        0.916667          10.983494       0.916667   \n",
       "5            13.804217        1.000000          12.816130       1.000000   \n",
       "6            13.563750        1.000000          12.567133       1.000000   \n",
       "7            13.682346        1.000000          13.030948       1.000000   \n",
       "8            13.211938        1.000000          12.224991       1.000000   \n",
       "9            13.141296        1.000000          12.417281       1.000000   \n",
       "10           19.916450        0.583333          18.190182       0.666667   \n",
       "11           17.683054        0.625000          16.488584       0.750000   \n",
       "12           16.480502        0.750000          15.017699       0.791667   \n",
       "13           15.109884        0.750000          13.832673       0.791667   \n",
       "14           14.454401        0.750000          13.264270       0.791667   \n",
       "15           11.922303        0.750000          10.269991       0.750000   \n",
       "16           10.635867        0.791667           9.122565       0.875000   \n",
       "17            9.938292        0.875000           8.449329       0.916667   \n",
       "18            9.589591        0.875000           8.334304       0.958333   \n",
       "19            9.425490        1.000000           8.493040       1.000000   \n",
       "20           18.005885        0.708333          14.195393       0.750000   \n",
       "21           18.219790        0.666667          15.287306       0.750000   \n",
       "22           19.674153        0.708333          16.183878       0.791667   \n",
       "23           22.385168        0.666667          18.810923       0.750000   \n",
       "24           22.946857        0.666667          18.681091       0.750000   \n",
       "25           14.350750        0.750000          13.293393       0.833333   \n",
       "26           14.535286        0.750000          13.726700       0.791667   \n",
       "27           17.570472        0.666667          15.777624       0.708333   \n",
       "28           19.295114        0.625000          18.475412       0.666667   \n",
       "29           22.173845        0.583333          20.284304       0.625000   \n",
       "30           14.418984        1.000000          13.160827       1.000000   \n",
       "31           15.269656        1.000000          14.318181       1.000000   \n",
       "32           13.589777        1.000000          12.779006       1.000000   \n",
       "33           13.174960        0.958333          12.465360       1.000000   \n",
       "34           13.192427        0.916667          12.166991       0.958333   \n",
       "35           38.364751        0.583333          36.686709       0.583333   \n",
       "36           35.287454        0.583333          33.126264       0.583333   \n",
       "37           33.160320        0.625000          31.136697       0.666667   \n",
       "38           29.832046        0.708333          28.171050       0.708333   \n",
       "39           25.781804        0.750000          23.729855       0.750000   \n",
       "40           13.056178        0.708333          11.716176       0.750000   \n",
       "41           15.089110        0.666667          14.122232       0.708333   \n",
       "42           18.415771        0.625000          17.380946       0.625000   \n",
       "43           19.279011        0.583333          18.152978       0.583333   \n",
       "44           20.421874        0.541667          19.277758       0.583333   \n",
       "45           16.387427        0.416667          14.841884       0.458333   \n",
       "46           15.694935        0.416667          14.191725       0.500000   \n",
       "47           13.957478        0.458333          12.643265       0.583333   \n",
       "48           13.216395        0.500000          11.871641       0.500000   \n",
       "49           11.876936        0.458333          10.246712       0.500000   \n",
       "\n",
       "    QuantileLoss[0.85]  Coverage[0.85]  QuantileLoss[0.9]  Coverage[0.9]  \\\n",
       "0             9.535338        1.000000           7.724808       1.000000   \n",
       "1             9.724944        1.000000           8.210302       1.000000   \n",
       "2             9.583450        1.000000           7.658261       1.000000   \n",
       "3             9.766723        1.000000           7.985700       1.000000   \n",
       "4             9.394270        1.000000           7.721919       1.000000   \n",
       "5            11.172144        1.000000           9.024492       1.000000   \n",
       "6            11.219251        1.000000           9.162633       1.000000   \n",
       "7            11.471467        1.000000           9.122589       1.000000   \n",
       "8            10.976226        1.000000           9.042314       1.000000   \n",
       "9            11.365704        1.000000           9.253060       1.000000   \n",
       "10           15.076023        0.750000          10.590061       0.791667   \n",
       "11           13.904601        0.750000           9.538211       0.833333   \n",
       "12           12.774426        0.791667           9.447886       0.875000   \n",
       "13           11.446580        0.833333           9.027000       0.916667   \n",
       "14           11.985966        0.875000          10.143289       0.916667   \n",
       "15            8.339809        0.833333           5.896901       0.875000   \n",
       "16            7.706726        0.916667           5.936623       0.916667   \n",
       "17            7.078583        0.916667           5.397418       0.958333   \n",
       "18            7.071426        1.000000           5.686759       1.000000   \n",
       "19            7.436285        1.000000           5.828531       1.000000   \n",
       "20           11.090756        0.833333           8.948596       1.000000   \n",
       "21           12.071813        0.958333           9.892691       1.000000   \n",
       "22           12.044741        0.833333           9.431882       1.000000   \n",
       "23           14.973244        0.833333          10.175970       0.958333   \n",
       "24           14.325852        0.791667           9.594576       0.916667   \n",
       "25           10.950468        0.875000           8.441165       0.916667   \n",
       "26           12.165871        0.833333           9.516813       0.833333   \n",
       "27           13.811710        0.750000           8.778838       0.750000   \n",
       "28           16.460173        0.666667          11.090885       0.750000   \n",
       "29           17.094936        0.625000          11.670557       0.666667   \n",
       "30           11.498629        1.000000           9.539135       1.000000   \n",
       "31           12.589408        1.000000          10.000469       1.000000   \n",
       "32           11.752058        1.000000           9.784720       1.000000   \n",
       "33           11.269158        1.000000           9.253498       1.000000   \n",
       "34           10.930972        1.000000           9.028704       1.000000   \n",
       "35           34.333453        0.625000          30.918752       0.625000   \n",
       "36           30.384987        0.625000          26.352150       0.625000   \n",
       "37           28.194545        0.666667          24.462593       0.708333   \n",
       "38           25.439794        0.708333          20.464149       0.750000   \n",
       "39           20.389908        0.750000          16.059383       0.791667   \n",
       "40           10.266243        0.791667           7.709159       0.875000   \n",
       "41           12.262899        0.708333           9.679443       0.791667   \n",
       "42           14.709410        0.666667          11.761991       0.750000   \n",
       "43           16.686868        0.625000          12.317728       0.666667   \n",
       "44           17.395408        0.583333          13.599509       0.625000   \n",
       "45           13.142396        0.541667          10.680427       0.583333   \n",
       "46           11.990767        0.500000           9.135106       0.583333   \n",
       "47           11.318431        0.583333           7.847360       0.625000   \n",
       "48           10.088644        0.500000           7.755532       0.625000   \n",
       "49            8.512246        0.625000           6.157311       0.708333   \n",
       "\n",
       "    QuantileLoss[0.95]  Coverage[0.95]  \n",
       "0             5.157125        1.000000  \n",
       "1             5.471453        1.000000  \n",
       "2             5.216567        1.000000  \n",
       "3             5.461416        1.000000  \n",
       "4             5.289974        1.000000  \n",
       "5             5.866569        1.000000  \n",
       "6             5.864446        1.000000  \n",
       "7             5.963617        1.000000  \n",
       "8             6.156625        1.000000  \n",
       "9             6.211123        1.000000  \n",
       "10            5.047673        0.958333  \n",
       "11            4.908834        0.958333  \n",
       "12            5.502651        0.958333  \n",
       "13            6.139118        0.958333  \n",
       "14            6.653918        0.958333  \n",
       "15            2.980712        1.000000  \n",
       "16            3.392868        0.958333  \n",
       "17            3.277453        1.000000  \n",
       "18            3.664867        1.000000  \n",
       "19            3.729641        1.000000  \n",
       "20            5.918934        1.000000  \n",
       "21            6.679425        1.000000  \n",
       "22            6.491683        1.000000  \n",
       "23            5.922300        1.000000  \n",
       "24            5.699961        0.958333  \n",
       "25            5.907164        1.000000  \n",
       "26            5.132470        1.000000  \n",
       "27            4.439254        0.958333  \n",
       "28            6.456314        0.875000  \n",
       "29            5.921161        0.916667  \n",
       "30            6.276026        1.000000  \n",
       "31            6.585096        1.000000  \n",
       "32            6.498848        1.000000  \n",
       "33            6.627076        1.000000  \n",
       "34            6.007921        1.000000  \n",
       "35           24.395038        0.666667  \n",
       "36           18.797424        0.708333  \n",
       "37           17.984768        0.708333  \n",
       "38           13.415492        0.791667  \n",
       "39            8.383249        0.916667  \n",
       "40            4.914773        0.958333  \n",
       "41            5.622566        0.875000  \n",
       "42            3.559619        0.916667  \n",
       "43            6.585830        0.708333  \n",
       "44            6.270064        0.708333  \n",
       "45            6.319313        0.666667  \n",
       "46            5.220434        0.708333  \n",
       "47            3.671637        0.750000  \n",
       "48            4.138754        0.791667  \n",
       "49            2.925594        0.875000  \n",
       "\n",
       "[50 rows x 51 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            0\n",
      "2021-01-04 00:00:00 -0.452626\n",
      "2021-01-04 01:00:00 -0.725134\n",
      "2021-01-04 02:00:00 -0.866961\n",
      "2021-01-04 03:00:00 -1.406889\n",
      "2021-01-04 04:00:00 -1.463340\n",
      "...                       ...\n",
      "2021-01-08 19:00:00  0.363605\n",
      "2021-01-08 20:00:00  0.258066\n",
      "2021-01-08 21:00:00  0.136216\n",
      "2021-01-08 22:00:00 -0.265441\n",
      "2021-01-08 23:00:00 -0.310883\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='0', samples=array([[ 0.5917033 ,  0.17943457,  5.9470663 , ...,  0.1563657 ,\n",
      "         0.9213214 , -1.089893  ],\n",
      "       [-0.87291616,  1.1067609 , -1.0934265 , ..., -0.6697999 ,\n",
      "        -1.4105551 , -1.918352  ],\n",
      "       [-2.175894  ,  0.6340908 ,  2.8945315 , ...,  0.34995815,\n",
      "        -0.93104243, -0.73153716],\n",
      "       ...,\n",
      "       [-0.72963417, -0.18709742, -0.54057604, ...,  0.49806985,\n",
      "         4.353466  ,  0.32596883],\n",
      "       [ 0.12265743, -0.5837308 , -0.06644715, ..., -0.30216372,\n",
      "        -0.7128781 , -4.8317165 ],\n",
      "       [ 0.01329204, -1.1261461 , -1.9411546 , ...,  2.115775  ,\n",
      "        -0.53753024,  0.3257546 ]], dtype=float32), start_date=Period('2021-01-08 00:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 01:00:00 -0.725134\n",
      "2021-01-04 02:00:00 -0.866961\n",
      "2021-01-04 03:00:00 -1.406889\n",
      "2021-01-04 04:00:00 -1.463340\n",
      "2021-01-04 05:00:00 -1.555979\n",
      "...                       ...\n",
      "2021-01-08 20:00:00  0.258066\n",
      "2021-01-08 21:00:00  0.136216\n",
      "2021-01-08 22:00:00 -0.265441\n",
      "2021-01-08 23:00:00 -0.310883\n",
      "2021-01-09 00:00:00 -0.539280\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='0', samples=array([[ 0.34953448,  0.5775471 , -3.0035622 , ...,  1.1116486 ,\n",
      "        -0.41730037,  0.9541811 ],\n",
      "       [ 0.74260634,  0.2897837 , -0.3378229 , ...,  0.10396919,\n",
      "         0.7250833 ,  0.83487654],\n",
      "       [-1.964686  , -0.03117516,  1.7132051 , ..., -0.05534397,\n",
      "         1.9122767 ,  0.10047993],\n",
      "       ...,\n",
      "       [ 0.62026775, -0.3437658 , -0.10584996, ..., -0.749128  ,\n",
      "        -0.41903114,  0.08070856],\n",
      "       [-0.39063302,  0.31341103, -0.00356336, ..., -1.0135603 ,\n",
      "        -0.11892426,  2.057225  ],\n",
      "       [ 0.7944235 ,  1.4878722 ,  0.02807295, ..., -0.02896769,\n",
      "        -0.0465153 ,  0.23593667]], dtype=float32), start_date=Period('2021-01-08 01:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 02:00:00 -0.866961\n",
      "2021-01-04 03:00:00 -1.406889\n",
      "2021-01-04 04:00:00 -1.463340\n",
      "2021-01-04 05:00:00 -1.555979\n",
      "2021-01-04 06:00:00 -1.573611\n",
      "...                       ...\n",
      "2021-01-08 21:00:00  0.136216\n",
      "2021-01-08 22:00:00 -0.265441\n",
      "2021-01-08 23:00:00 -0.310883\n",
      "2021-01-09 00:00:00 -0.539280\n",
      "2021-01-09 01:00:00 -0.836770\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='0', samples=array([[-1.5557535 , -0.5271933 ,  1.2279493 , ..., -2.3360696 ,\n",
      "        -5.287822  ,  0.3345456 ],\n",
      "       [ 0.16097698,  0.06173237,  0.16469707, ..., -0.17240237,\n",
      "        -0.06653884, -3.402873  ],\n",
      "       [-1.011638  , -1.1172636 , -1.049241  , ...,  1.0646564 ,\n",
      "        -0.32711044, -0.64786714],\n",
      "       ...,\n",
      "       [ 1.6627465 ,  1.2531115 ,  0.863833  , ...,  0.29814777,\n",
      "         0.5209583 ,  0.1035707 ],\n",
      "       [-0.348255  , -3.0727131 , -1.7554983 , ...,  0.6193584 ,\n",
      "         0.23701082, -1.3859357 ],\n",
      "       [-0.29365036,  2.2352166 ,  0.37064052, ..., -0.5407836 ,\n",
      "         0.03807281, -0.3658971 ]], dtype=float32), start_date=Period('2021-01-08 02:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 03:00:00 -1.406889\n",
      "2021-01-04 04:00:00 -1.463340\n",
      "2021-01-04 05:00:00 -1.555979\n",
      "2021-01-04 06:00:00 -1.573611\n",
      "2021-01-04 07:00:00 -1.552965\n",
      "...                       ...\n",
      "2021-01-08 22:00:00 -0.265441\n",
      "2021-01-08 23:00:00 -0.310883\n",
      "2021-01-09 00:00:00 -0.539280\n",
      "2021-01-09 01:00:00 -0.836770\n",
      "2021-01-09 02:00:00 -0.932413\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='0', samples=array([[ 0.0549791 , -0.4312615 ,  0.5328164 , ..., -2.6182735 ,\n",
      "         0.5670952 , -0.8114874 ],\n",
      "       [-0.15747681, -0.11659974,  0.6716345 , ..., -0.39077985,\n",
      "        -0.7476808 ,  1.6395677 ],\n",
      "       [-0.0453245 , -0.6807156 ,  0.7885293 , ..., -1.0659964 ,\n",
      "        -0.3330115 ,  0.1629717 ],\n",
      "       ...,\n",
      "       [-0.17243989,  1.6907179 , -0.30122972, ..., -0.08398856,\n",
      "         0.46901095, -0.19615129],\n",
      "       [-0.02655525,  3.9918633 ,  0.58282703, ..., -0.60742784,\n",
      "         0.14742167, -0.07967077],\n",
      "       [-0.37109903, -0.9794616 , -0.19458   , ...,  0.60453075,\n",
      "        -0.1488631 , -0.38629213]], dtype=float32), start_date=Period('2021-01-08 03:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 04:00:00 -1.463340\n",
      "2021-01-04 05:00:00 -1.555979\n",
      "2021-01-04 06:00:00 -1.573611\n",
      "2021-01-04 07:00:00 -1.552965\n",
      "2021-01-04 08:00:00 -1.347372\n",
      "...                       ...\n",
      "2021-01-08 23:00:00 -0.310883\n",
      "2021-01-09 00:00:00 -0.539280\n",
      "2021-01-09 01:00:00 -0.836770\n",
      "2021-01-09 02:00:00 -0.932413\n",
      "2021-01-09 03:00:00 -0.906552\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='0', samples=array([[ 0.24247016,  2.603932  , -0.14949276, ..., -0.8990808 ,\n",
      "         0.3841135 , -1.9130344 ],\n",
      "       [-0.43213716, -0.12991196,  0.34969446, ...,  0.38237306,\n",
      "         0.6515667 , -0.45213133],\n",
      "       [ 0.03028291,  0.36156106,  0.33976316, ...,  0.71015155,\n",
      "        -0.48800755, -0.00538615],\n",
      "       ...,\n",
      "       [ 0.14286184,  0.6660988 ,  1.5294433 , ..., -0.4598307 ,\n",
      "         2.813528  , -4.763042  ],\n",
      "       [-0.02542962,  0.05715119,  0.99063605, ...,  0.7786927 ,\n",
      "        -0.25454998,  0.26517096],\n",
      "       [ 0.1100235 ,  1.2826585 , -1.2289622 , ..., -0.8919869 ,\n",
      "        -0.41054896, -0.10714486]], dtype=float32), start_date=Period('2021-01-08 04:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 00:00:00 -1.186081\n",
      "2021-01-04 01:00:00 -1.092264\n",
      "2021-01-04 02:00:00 -1.034374\n",
      "2021-01-04 03:00:00 -0.798692\n",
      "2021-01-04 04:00:00 -0.832752\n",
      "...                       ...\n",
      "2021-01-08 19:00:00 -0.953122\n",
      "2021-01-08 20:00:00 -1.189599\n",
      "2021-01-08 21:00:00 -1.140551\n",
      "2021-01-08 22:00:00 -1.323811\n",
      "2021-01-08 23:00:00 -0.999085\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='1', samples=array([[ 0.517008  , -0.16790253,  0.41021693, ...,  1.0040312 ,\n",
      "         0.48292693,  0.27472776],\n",
      "       [ 0.05363385, -1.1801087 ,  0.40683505, ..., -0.00898463,\n",
      "        -0.09320032, -0.45182613],\n",
      "       [-0.7530923 ,  0.1601729 ,  0.37350622, ...,  0.69906694,\n",
      "         0.08335374, -1.3909528 ],\n",
      "       ...,\n",
      "       [ 0.30795872,  0.6603417 ,  2.9315145 , ...,  1.1840264 ,\n",
      "        -0.64619637, -0.11077816],\n",
      "       [-0.26596907, -1.3406583 , -0.12394336, ..., -0.649721  ,\n",
      "         0.01837981, -1.1317148 ],\n",
      "       [-1.4711342 , -0.9951628 , -0.26120755, ..., -0.47206673,\n",
      "         0.12068225, -0.79537845]], dtype=float32), start_date=Period('2021-01-08 00:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 01:00:00 -1.092264\n",
      "2021-01-04 02:00:00 -1.034374\n",
      "2021-01-04 03:00:00 -0.798692\n",
      "2021-01-04 04:00:00 -0.832752\n",
      "2021-01-04 05:00:00 -0.460483\n",
      "...                       ...\n",
      "2021-01-08 20:00:00 -1.189599\n",
      "2021-01-08 21:00:00 -1.140551\n",
      "2021-01-08 22:00:00 -1.323811\n",
      "2021-01-08 23:00:00 -0.999085\n",
      "2021-01-09 00:00:00 -0.798585\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='1', samples=array([[ 1.6525552 ,  1.2752604 ,  0.47155225, ...,  0.7667197 ,\n",
      "         0.08774728,  1.0447763 ],\n",
      "       [-0.9039348 ,  0.03912942, -0.625831  , ..., -1.7111212 ,\n",
      "         0.54819715, -0.9879093 ],\n",
      "       [-0.06353936, -0.7452394 ,  0.1249228 , ..., -0.77286583,\n",
      "         0.13645066, -0.4470645 ],\n",
      "       ...,\n",
      "       [-0.5460273 ,  0.84934115, -0.37117136, ...,  2.2136495 ,\n",
      "        -0.19428112, -0.60477775],\n",
      "       [-0.62576073, -0.61838955,  0.17857724, ...,  0.15815435,\n",
      "         0.2740795 ,  0.3984856 ],\n",
      "       [ 1.9201037 ,  1.3831711 , -2.7109675 , ..., -0.27582875,\n",
      "        -0.4794794 ,  1.3083526 ]], dtype=float32), start_date=Period('2021-01-08 01:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 02:00:00 -1.034374\n",
      "2021-01-04 03:00:00 -0.798692\n",
      "2021-01-04 04:00:00 -0.832752\n",
      "2021-01-04 05:00:00 -0.460483\n",
      "2021-01-04 06:00:00 -0.442173\n",
      "...                       ...\n",
      "2021-01-08 21:00:00 -1.140551\n",
      "2021-01-08 22:00:00 -1.323811\n",
      "2021-01-08 23:00:00 -0.999085\n",
      "2021-01-09 00:00:00 -0.798585\n",
      "2021-01-09 01:00:00 -0.650716\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='1', samples=array([[ 0.7155065 , -3.1810853 ,  0.2009593 , ...,  0.19701616,\n",
      "         0.16973408, -2.0378456 ],\n",
      "       [ 4.2871723 ,  0.5559389 ,  0.5859232 , ...,  3.1919844 ,\n",
      "         1.3297276 , -1.906781  ],\n",
      "       [ 0.04838995, -3.7263875 , -0.30179343, ...,  0.16947143,\n",
      "         0.4500835 , -0.93769485],\n",
      "       ...,\n",
      "       [ 0.10290829,  0.19612125, -0.11041308, ...,  0.77153736,\n",
      "         0.382875  ,  1.9302057 ],\n",
      "       [ 1.5093046 , -1.470672  ,  0.26609662, ...,  5.5553126 ,\n",
      "        -2.4083674 , -1.4165716 ],\n",
      "       [ 2.7383883 , -1.6495152 ,  0.28749272, ..., -0.08231414,\n",
      "        -0.25500798, -0.02645   ]], dtype=float32), start_date=Period('2021-01-08 02:00', 'H'))\n",
      "                            0\n",
      "2021-01-04 03:00:00 -0.798692\n",
      "2021-01-04 04:00:00 -0.832752\n",
      "2021-01-04 05:00:00 -0.460483\n",
      "2021-01-04 06:00:00 -0.442173\n",
      "2021-01-04 07:00:00 -0.282067\n",
      "...                       ...\n",
      "2021-01-08 22:00:00 -1.323811\n",
      "2021-01-08 23:00:00 -0.999085\n",
      "2021-01-09 00:00:00 -0.798585\n",
      "2021-01-09 01:00:00 -0.650716\n",
      "2021-01-09 02:00:00 -0.352277\n",
      "\n",
      "[120 rows x 1 columns]\n",
      "gluonts.model.forecast.SampleForecast(info=None, item_id='1', samples=array([[ 0.79376805, -3.4047341 , -0.98973536, ..., -0.5132261 ,\n",
      "        -2.2559884 , -0.4633082 ],\n",
      "       [ 0.1981264 ,  1.3566997 ,  0.3851365 , ..., -0.47760272,\n",
      "         0.27383792,  0.72762567],\n",
      "       [-0.5741686 ,  0.4312104 , -0.20693807, ..., -1.0227925 ,\n",
      "        -0.17069778, -0.02637723],\n",
      "       ...,\n",
      "       [ 2.7604818 , -1.0923676 ,  1.588908  , ..., -1.462815  ,\n",
      "        -0.02322512, -1.8118238 ],\n",
      "       [-0.33770788, -0.7128686 ,  0.49423736, ...,  0.8660393 ,\n",
      "        -1.4304577 , -2.3727286 ],\n",
      "       [ 0.68269295,  0.46733788,  3.5818307 , ..., -0.77254444,\n",
      "         1.0658556 ,  0.15253262]], dtype=float32), start_date=Period('2021-01-08 03:00', 'H'))\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts_pytorch, tss_pytorch)), 9):\n",
    "    # ax = plt.subplot(3, 3, idx + 1)\n",
    "    print(ts[-5 * prediction_length :].to_timestamp())\n",
    "    print(forecast)\n",
    "    # plt.plot(ts[-5 * prediction_length :].to_timestamp(), label=\"target\")\n",
    "    # forecast.plot()\n",
    "    # plt.xticks(rotation=60)\n",
    "    # ax.xaxis.set_major_formatter(date_formater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freqdiff310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d3c213ab284d513e0b425da88e0322a8b7a04151fe70983bee321705625addc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
