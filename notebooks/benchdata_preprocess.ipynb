{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "root_pth = \"/home/user/data/THU-timeseries\"\n",
    "# root_pth = \"/mnt/ExtraDisk/wcx/research/THU-timeseries\"\n",
    "all_data_pth = [\n",
    "    # \"dataset/MFRED_clean.csv\",\n",
    "    # \"ETT-small/ETTh1.csv\",\n",
    "    # \"ETT-small/ETTh2.csv\",\n",
    "    # \"ETT-small/ETTm1.csv\",\n",
    "    # \"ETT-small/ETTm2.csv\",\n",
    "    # 'exchange_rate/exchange_rate.csv',\n",
    "    # 'illness/national_illness.csv',\n",
    "    # 'weather/weather.csv',\n",
    "    # 'traffic/traffic.csv',\n",
    "    'electricity/electricity.csv',\n",
    "]\n",
    "for data_pth in all_data_pth:\n",
    "    df = pd.read_csv(os.path.join(root_pth, data_pth), index_col=0, parse_dates=True)\n",
    "    n_timestep = len(df)\n",
    "    num_train = int(n_timestep * 0.7)\n",
    "    df = np.lib.stride_tricks.sliding_window_view(df['OT'].values.flatten(), 96*2)\n",
    "    df = (df - df.mean(axis=1, keepdims=True))/df.std(axis=1, keepdims=True)\n",
    "    print(df.std())\n",
    "    \n",
    "    # sns.jointplot(df, x=0, y=1)\n",
    "        \n",
    "    # scaler = StandardScaler()\n",
    "    # scaler.fit(df[:num_train])\n",
    "    # df[df.columns] = scaler.transform(df)\n",
    "    # df.index = pd.date_range('2019-01-01', periods=len(df), freq='5min')\n",
    "        \n",
    "    # df.to_csv(os.path.join(root_pth, 'MFRED_scaled.csv'))\n",
    "    # long_df = []\n",
    "    # for c in df.columns.tolist():\n",
    "    #     temp_df = df[[c]].copy()\n",
    "    #     temp_df['unique_id'] = c\n",
    "    #     temp_df = temp_df.reset_index()\n",
    "    #     temp_df = temp_df.rename(columns={c:'y','date':'ds'})\n",
    "    #     if data_pth.__contains__('ETTh'):\n",
    "    #         num_train = 12 * 30 * 24\n",
    "    #         num_test = 4 * 30 * 24\n",
    "    #         num_vali = 4 * 30 * 24\n",
    "    #         temp_df = temp_df[:num_train+num_vali+num_test]\n",
    "    #     elif data_pth.__contains__('ETTm'):\n",
    "    #         num_train = 12 * 30 * 24 * 4\n",
    "    #         num_test = 4 * 30 * 24 * 4\n",
    "    #         num_vali = 4 * 30 * 24 * 4\n",
    "    #         temp_df = temp_df[:num_train+num_vali+num_test]\n",
    "    #     long_df.append(temp_df)\n",
    "    # long_df = pd.concat(long_df)\n",
    "    # long_df = long_df.reset_index(drop=True)\n",
    "    # long_df.to_csv(os.path.join(root_pth, data_pth[:-4]+'_NF.csv'), index=False)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasetsforecast.long_horizon import LongHorizon, LongHorizonInfo\n",
    "import logging\n",
    "import os\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import (\n",
    "    NHITS,\n",
    "    DLinear,\n",
    "    PatchTST,\n",
    "    TimesNet,\n",
    "    # iTransformer,\n",
    "    # TFT,\n",
    "    Autoformer,\n",
    "    # FEDformer,\n",
    "    # LSTM,\n",
    "    # MLP,\n",
    "    # NBEATSx,\n",
    "    # DeepAR,\n",
    ")\n",
    "from neuralforecast.losses.numpy import mse, mae\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss\n",
    "from neuralforecast.losses.numpy import mqloss, mse, mae\n",
    "from src.utils.metrics import calculate_metrics, get_bench_metrics\n",
    "import pickle\n",
    "\n",
    "# Change this to your own data to try the model\n",
    "print(LongHorizonInfo['ECL'].test_size)\n",
    "Y_df, _, _ = LongHorizon.load(directory='/home/user/data/NF_longterm', group='ECL')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "\n",
    "# For this excercise we are going to take 960 timestamps as validation and test\n",
    "n_time = len(Y_df.ds.unique())\n",
    "num_train = int(n_time * 0.7)\n",
    "num_test = int(n_time * 0.2)\n",
    "print(num_test)\n",
    "num_vali = n_time - num_train - num_test\n",
    "# num_train = 12 * 30 * 24\n",
    "# num_test = 4 * 30 * 24\n",
    "# num_vali = 4 * 30 * 24\n",
    "        \n",
    "# val_size = 96*10\n",
    "# test_size = 96*10\n",
    "\n",
    "Y_df = Y_df[Y_df['unique_id'] == 'OT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_hat_df[\"y\"].values.reshape(-1, pred_len, 1)\n",
    "print(y_true.shape)\n",
    "y_true[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE METRICS\n",
    "ds = [\n",
    "    \"ETTh1\",\n",
    "    \"ETTh2\",\n",
    "    \"ETTm1\",\n",
    "    \"ETTm2\",\n",
    "    \"ECL\",\n",
    "    \"Exchange\",\n",
    "    \"TrafficL\",\n",
    "    \"Weather\",\n",
    "]\n",
    "pred_len = [96, 192, 336, 720]\n",
    "save_dir = \"/mnt/ExtraDisk/wcx/research/benchmarks\"\n",
    "all_df = []\n",
    "for d in ds:\n",
    "    ds_df = []\n",
    "    for pl in pred_len:\n",
    "        result_path = os.path.join(save_dir, f\"{d}_96_{pl}_U\",\"results.csv\")\n",
    "        df = pd.read_csv(result_path, index_col=0)\n",
    "        df.index.name = 'model'\n",
    "        df = df.reset_index()\n",
    "        df = df.groupby('model').mean()\n",
    "        df = df.drop(columns=['MAE', 'iter'])\n",
    "        df = df.stack()\n",
    "        df = pd.DataFrame(df, columns=[pl]).transpose()\n",
    "        ds_df.append(df)\n",
    "    ds_df = pd.concat(ds_df)\n",
    "    ds_df.index.name = 'pred_len'\n",
    "    ds_df['dataset'] = d\n",
    "    ds_df = ds_df.reset_index()\n",
    "    ds_df = ds_df.set_index(['dataset','pred_len'])\n",
    "    all_df.append(ds_df)\n",
    "all_df = pd.concat(all_df)\n",
    "all_df.to_csv(os.path.join(save_dir, 'bench_result.csv'))\n",
    "# print(all_df.to_latex(float_format=\"{:.3f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ds = {\n",
    "        \"ETTh1\": \"ETTh1\",\n",
    "        \"ETTh2\": \"ETTh2\",\n",
    "        \"ETTm1\": \"ETTm1\",\n",
    "        \"ETTm2\": \"ETTm2\",\n",
    "        \"ECL\": \"electricity\",\n",
    "        \"Exchange\": \"exchange_rate\",\n",
    "        \"TrafficL\": \"traffic\",\n",
    "        \"Weather\": \"weather\",\n",
    "        \"MFRED\": \"mfred\",\n",
    "    }\n",
    "\n",
    "for d in ds:\n",
    "    print(d)\n",
    "    if d=='Weather':\n",
    "        data_dir_nf = '/mnt/ExtraDisk/wcx/research'\n",
    "        dataset_nf = d\n",
    "        data_dir_thu = '/mnt/ExtraDisk/wcx/research/THU-timeseries'\n",
    "        dataset_thu = f\"{'ETT-small' if ds[d].__contains__('ETT') else ds[d]}/{ds[d]}.csv\"\n",
    "        csv_thu = os.path.join(data_dir_thu, dataset_thu)\n",
    "        \n",
    "        # THU\n",
    "        df_thu = pd.read_csv(csv_thu, index_col=0, parse_dates=True)[['OT']]\n",
    "        if d.__contains__(\"ETTh\"):\n",
    "            num_train = 12 * 30 * 24\n",
    "            # num_test = 4 * 30 * 24\n",
    "            # num_vali = 4 * 30 * 24\n",
    "        elif d.__contains__(\"ETTm\"):\n",
    "            num_train = 12 * 30 * 24 * 4\n",
    "            # num_test = 4 * 30 * 24 * 4\n",
    "            # num_vali = 4 * 30 * 24 * 4\n",
    "        else:\n",
    "            num_train = int(len(df_thu) * 0.7)\n",
    "            # num_test = int(len(Y_df) * 0.2)\n",
    "            # num_vali = len(Y_df) - num_train - num_test\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df_thu.values[:num_train])\n",
    "        df_thu_value = scaler.transform(df_thu.values)\n",
    "        \n",
    "            \n",
    "        # NF\n",
    "        Y_df, _, _ = LongHorizon.load(directory=data_dir_nf, group=dataset_nf)\n",
    "        Y_df[\"ds\"] = pd.to_datetime(Y_df[\"ds\"])\n",
    "        df_nf = Y_df[Y_df[\"unique_id\"] == \"OT\"]\n",
    "        df_nf = df_nf.drop(columns=['unique_id'])\n",
    "        df_nf = df_nf.set_index('ds')\n",
    "        \n",
    "        if df_thu_value.shape != df_nf.values.shape:\n",
    "            print(\"shape is not the same\")\n",
    "            print(f'{d}')\n",
    "            print(df_thu_value.shape)\n",
    "            print(df_nf.values.shape)\n",
    "            max_len = min(len(df_thu_value), len(df_nf.values))\n",
    "        else:\n",
    "            max_len = len(df_thu_value)\n",
    "        \n",
    "        close = np.allclose(df_thu_value.flatten()[:max_len], df_nf.values.flatten()[:max_len])\n",
    "        close = np.allclose(df_thu_value.flatten()[-10000:], df_nf.values.flatten()[-10000:])\n",
    "        print(close)\n",
    "        if not close:\n",
    "            # plt.plot(df_thu_value.flatten()[-10000:])\n",
    "            # plt.plot(df_nf.values.flatten()[-10000:])\n",
    "            plt.scatter(df_thu_value.flatten()[-10000:], df_nf.values.flatten()[-10000:])\n",
    "        print('----'*10)\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.scatter(df_thu_value.flatten()[:max_len], df_nf.values.flatten()[:max_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from neuralforecast.losses.numpy import mse, mqloss\n",
    "\n",
    "# # SAVE METRICS\n",
    "ds = [\n",
    "    \"ETTh1\",\n",
    "    \"ETTh2\",\n",
    "    \"ETTm1\",\n",
    "    \"ETTm2\",\n",
    "    \"ECL\",\n",
    "    \"Exchange\",\n",
    "    \"TrafficL\",\n",
    "    \"Weather\",\n",
    "]\n",
    "quantiles = [0.05 * i for i in range(19)]\n",
    "# pred_len = [336]\n",
    "pred_len = [96, 192, 336, 720]\n",
    "save_dir = \"/mnt/ExtraDisk/wcx/research/benchmarks\"\n",
    "all_df = []\n",
    "for d in ds:\n",
    "    # if d != 'TrafficL':\n",
    "    #     continue\n",
    "    ds_df = []\n",
    "    for pl in pred_len:\n",
    "        label_path = os.path.join(save_dir, f\"{d}_96_{pl}_U\", \"true.npy\")\n",
    "        pred_path = os.path.join(save_dir, f\"{d}_96_{pl}_U\", \"pred_PatchTST_0.npy\")\n",
    "        y_true = np.load(label_path)\n",
    "        y_pred = np.load(pred_path)\n",
    "        y_true_fft = np.fft.rfft(y_true[0].flatten(), norm=\"ortho\")\n",
    "        y_true_fft[0] = 0\n",
    "        y_tr_fft_abs = np.abs(y_true_fft)\n",
    "        theta = np.arctan2(y_true_fft.imag, y_true_fft.real)\n",
    "        phi_r_int = np.where(\n",
    "            np.isinf(y_tr_fft_abs),\n",
    "            np.ones_like(y_tr_fft_abs),\n",
    "            ((y_tr_fft_abs - 1) / (y_tr_fft_abs + 1)),\n",
    "        )\n",
    "        phi = np.arcsin(phi_r_int)\n",
    "        # print(theta[0])\n",
    "        print(theta[-1])\n",
    "        # y_true = y_true[::pl].flatten()\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(theta)\n",
    "        # ax.plot(y_pred[333, ..., 9].flatten())\n",
    "\n",
    "        ax.set_title(d)\n",
    "        # plt.plot(y_true[126].flatten())\n",
    "        # plt.plot(y_pred[126, ..., 9].flatten())\n",
    "        break\n",
    "    # break\n",
    "#         df.index.name = 'model'\n",
    "#         df = df.reset_index()\n",
    "#         df = df.groupby('model').mean()\n",
    "#         df = df.drop(columns=['MAE', 'iter'])\n",
    "#         df = df.stack()\n",
    "#         df = pd.DataFrame(df, columns=[pl]).transpose()\n",
    "#         ds_df.append(df)\n",
    "#     ds_df = pd.concat(ds_df)\n",
    "#     ds_df.index.name = 'pred_len'\n",
    "#     ds_df['dataset'] = d\n",
    "#     ds_df = ds_df.reset_index()\n",
    "#     ds_df = ds_df.set_index(['dataset','pred_len'])\n",
    "#     all_df.append(ds_df)\n",
    "# all_df = pd.concat(all_df)\n",
    "# all_df.to_csv(os.path.join(save_dir, 'bench_result.csv'))\n",
    "# print(all_df.to_latex(float_format=\"{:.3f}\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "\n",
    "ds = {\n",
    "    \"ETTh1\": \"etth1\",\n",
    "    # \"ETTh2\": \"etth2\",\n",
    "    # \"ETTm1\": \"ettm1\",\n",
    "    # \"ETTm2\": \"ettm2\",\n",
    "    # \"ECL\": \"electricity\",\n",
    "    # \"Exchange\": \"exchange_rate\",\n",
    "    # \"TrafficL\": \"traffic\",\n",
    "    # \"Weather\": \"weather\",\n",
    "    # \"MFRED\": \"mfred\",\n",
    "}\n",
    "# pred_len = [288, 432, 576]\n",
    "pred_len = [96]\n",
    "# pred_len = [96, 192, 336, 720]\n",
    "save_dir = \"/home/user/data/FrequencyDiffusion/savings\"\n",
    "save_dir_bench = \"/home/user/data/NF_benchmark\"\n",
    "# save_dir = \"/mnt/ExtraDisk/wcx/research/FrequencyDiffusion/savings\"\n",
    "all_df = []\n",
    "\n",
    "for d in ds:\n",
    "    real_d = ds[d]\n",
    "    ds_df = []\n",
    "    for pl in pred_len:\n",
    "        print(d, pl)\n",
    "        result_path = os.path.join(save_dir, f\"{real_d}_{pl}_S\", \"test_dl.pt\")\n",
    "        test_dl = torch.load(result_path)\n",
    "        y_real = []\n",
    "        x = []\n",
    "        for b in test_dl:\n",
    "            x.append(b[\"observed_data\"].cpu().numpy())\n",
    "            y_real.append(b[\"future_data\"].cpu().numpy())\n",
    "        y_real = np.concatenate(y_real)\n",
    "        print(y_real.shape)\n",
    "        print(y_real.flatten()[:10])\n",
    "        print(y_real.flatten()[-10:])\n",
    "        # print(y_real[-1])\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #     x_norm = (x - x.mean(axis=1, keepdims=True))/x.std(axis=1, keepdims=True)\n",
    "    #     y_real_norm = (y_real - x.mean(axis=1, keepdims=True))/x.std(axis=1, keepdims=True)\n",
    "\n",
    "    #     fig, axs = plt.subplots(3,3)\n",
    "    #     axs = axs.flatten()\n",
    "    #     choose = np.random.randint(0, len(x), size=len(axs))\n",
    "    #     for i in range(len(axs)):\n",
    "    #         # axs[i].plot(range(0, x.shape[1]), x[choose[i], :, 0])\n",
    "    #         # axs[i].plot(range(0, x.shape[1]), np.mean(x[choose[i], :, 0], axis=0, keepdims=True).repeat(x.shape[1]), ls='--', c='grey')\n",
    "    #         # axs[i].plot(range(x.shape[1], x.shape[1]+y_real.shape[1]), y_real[choose[i], :, 0])\n",
    "    #         # axs[i].plot(range(x.shape[1], x.shape[1]+y_real.shape[1]), np.mean(y_real[choose[i], :, 0], axis=0, keepdims=True).repeat(y_real.shape[1]), ls='--', c='grey')\n",
    "\n",
    "    #         axs[i].plot(range(0, x_norm.shape[1]), x_norm[choose[i], :, 0])\n",
    "    #         axs[i].plot(range(0, x_norm.shape[1]), np.mean(x_norm[choose[i], :, 0], axis=0, keepdims=True).repeat(x.shape[1]), ls='--', c='grey')\n",
    "    #         axs[i].plot(range(x.shape[1], x.shape[1]+y_real.shape[1]), y_real_norm[choose[i], :, 0])\n",
    "    #         axs[i].plot(range(x.shape[1], x.shape[1]+y_real.shape[1]), np.mean(y_real_norm[choose[i], :, 0], axis=0, keepdims=True).repeat(y_real_norm.shape[1]), ls='--', c='grey')\n",
    "    #     # fig.suptitle(f'{d}-96-{pl}')\n",
    "    #     fig.tight_layout()\n",
    "    #     break\n",
    "    # break\n",
    "    # fig.savefig(f'../assets/{d}-96-{pl}.png')\n",
    "\n",
    "    # bench_path = os.path.join(save_dir_bench, f\"{d}_96_{pl}_S\", \"true.npy\")\n",
    "    # y_real_bench = np.load(bench_path)\n",
    "    # print(np.allclose(y_real, y_real_bench))\n",
    "    # # assert np.allclose(y_real, y_real_bench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../assets/bj_aq_online.csv')\n",
    "df = df.dropna(axis=1, how='all')\n",
    "for i, temp_df in df.groupby('station_id'):\n",
    "    temp_df = temp_df.drop(columns=['id', 'station_id'])\n",
    "    temp_df['time'] = pd.to_datetime(temp_df['time'])\n",
    "    temp_df = temp_df.sort_values('time')\n",
    "    temp_df = temp_df.set_index('time')\n",
    "    temp_df[:100].plot()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* FORECAST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECL</th>\n",
       "      <th>ETTh2</th>\n",
       "      <th>ETTm2</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>traffic</th>\n",
       "      <th>weather</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dlinear</th>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>0.3226</td>\n",
       "      <td>0.1913</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PatchTST</th>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSDI</th>\n",
       "      <td>0.4581</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>2.1230</td>\n",
       "      <td>1.2557</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSSD</th>\n",
       "      <td>1.0257</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>2.9004</td>\n",
       "      <td>1.9662</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>7.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3VAE</th>\n",
       "      <td>0.8450</td>\n",
       "      <td>1.3961</td>\n",
       "      <td>3.3449</td>\n",
       "      <td>2.1086</td>\n",
       "      <td>6.3583</td>\n",
       "      <td>1.5461</td>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMDM</th>\n",
       "      <td>0.4071</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.7885</td>\n",
       "      <td>0.1805</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr-diff</th>\n",
       "      <td>0.5287</td>\n",
       "      <td>0.2172</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.4801</td>\n",
       "      <td>0.2471</td>\n",
       "      <td>0.2078</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MADfreq_FactOnly_puncond0.5_bs64_fcst</th>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>2.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ECL   ETTh2   ETTm2  Exchange  \\\n",
       "Dlinear                                0.3926  0.2239  0.1255    0.3681   \n",
       "PatchTST                               0.4116  0.2026  0.1219    0.5154   \n",
       "CSDI                                   0.4581  0.2571  2.1230    1.2557   \n",
       "SSSD                                   1.0257  0.7201  0.8936    2.9004   \n",
       "D3VAE                                  0.8450  1.3961  3.3449    2.1086   \n",
       "TMDM                                   0.4071  0.2508  0.1789    0.7885   \n",
       "mr-diff                                0.5287  0.2172  0.1700    0.4801   \n",
       "MADfreq_FactOnly_puncond0.5_bs64_fcst  0.3692  0.2101  0.1273    0.4110   \n",
       "\n",
       "                                       traffic  weather     0  \n",
       "Dlinear                                 0.3226   0.1913  2.67  \n",
       "PatchTST                                0.1784   0.1889  2.00  \n",
       "CSDI                                    0.4991   0.1938  5.50  \n",
       "SSSD                                    1.9662   0.6905  7.17  \n",
       "D3VAE                                   6.3583   1.5461  7.67  \n",
       "TMDM                                    0.1805   0.2209  4.33  \n",
       "mr-diff                                 0.2471   0.2078  3.83  \n",
       "MADfreq_FactOnly_puncond0.5_bs64_fcst   0.2525   0.2132  2.83  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bs = 128\n",
    "# model_name = f\"MADtime_pl_Full_SETKS_FreqDoi_bs{bs}\"\n",
    "# model_name = f\"MADtime_pl_Full_SETKS_bs{bs}\"\n",
    "# model_name = f\"MADtime_pl_FactOnly_FreqDoi_bs{64}\"\n",
    "# model_name = f\"MADtime_pl_FactOnly_SETKS_FreqDoi_CFG_puncond0.8_bs{bs}_fcst\"\n",
    "# model_name = \"MADtime_FactOnly_SETKS_learnmean_freqdenoise_bs64_fast\"\n",
    "# model_name = \"MADtime_FactOnly_SETKS_learnmean_freqdenoise_puncond0.5_bs64_fcst\"\n",
    "model_name = \"MADfreq_FactOnly_puncond0.5_bs64_fcst\"\n",
    "# model_name = \"MADtime_FactOnly_SETKS_learnmean_freqdenoise_bs64_new\"\n",
    "\n",
    "# * BEST FCST\n",
    "# model_name = \"best_MADtime_pl_FactOnly_FreqDoi\"\n",
    "\n",
    "datasets = ['ECL','ETTh2','ETTm2','Exchange','Weather']\n",
    "\n",
    "new_df = pd.read_csv(f\"../assets/{model_name}.csv\")\n",
    "# new_df = pd.read_csv('../assets/MADtime_pl_doublenorm_FreqDenoise.csv')[['MSE']]\n",
    "# print(new_df)\n",
    "new_df = new_df.rename(columns={\"MSE\": model_name})\n",
    "new_df = new_df.drop(columns=[\"CRPS\", \"method\"])\n",
    "df = pd.read_csv(\"../assets/results_MSE.csv\", delimiter=\"\\t\")\n",
    "# print(df)\n",
    "\n",
    "df = pd.merge(df, new_df)\n",
    "\n",
    "# df = pd.concat([df, new_df], axis=1)\n",
    "df = df.groupby(\"dataset\").mean()\n",
    "# # df\n",
    "# df = df[['Dlinear', 'PatchTST', 'CSDI','D3VAE', 'SSSD', 'TMDM', 'mr-diff','MADtime_freqdenoise_bs128']]\n",
    "df = df[\n",
    "    [\n",
    "        \"Dlinear\",\n",
    "        \"PatchTST\",\n",
    "        \"CSDI\",\n",
    "        \"SSSD\",\n",
    "        \"D3VAE\",\n",
    "        \"TMDM\",\n",
    "        \"mr-diff\",\n",
    "        model_name,\n",
    "    ]\n",
    "]\n",
    "# df = df[['Dlinear', 'PatchTST', 'CSDI', 'SSSD', 'D3VAE','TMDM', 'mr-diff','MADfreq_pl_doublenorm_dp0.3','MADtime_freqdenoise']]\n",
    "df = df.T\n",
    "# df = df.drop(columns=['MFRED']).round(4)\n",
    "# df = df.drop(columns=[\"MFRED\", \"ETTh1\", \"ETTm1\"]).round(4)\n",
    "df = df.round(4)\n",
    "df = pd.concat([df, df.rank().mean(axis=1).round(2)], axis=1)\n",
    "df\n",
    "\n",
    "# print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Refinement results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECL</th>\n",
       "      <th>ETTh2</th>\n",
       "      <th>ETTm2</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>traffic</th>\n",
       "      <th>weather</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PatchTST</th>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MADfreq_puncond0.5_bs64_refine</th>\n",
       "      <td>0.8915</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>0.1311</td>\n",
       "      <td>0.4499</td>\n",
       "      <td>1.8220</td>\n",
       "      <td>0.1904</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   ECL   ETTh2   ETTm2  Exchange  traffic  \\\n",
       "PatchTST                        0.4116  0.2026  0.1219    0.5154   0.1784   \n",
       "MADfreq_puncond0.5_bs64_refine  0.8915  0.2586  0.1311    0.4499   1.8220   \n",
       "\n",
       "                                weather     0  \n",
       "PatchTST                         0.1889  1.17  \n",
       "MADfreq_puncond0.5_bs64_refine   0.1904  1.83  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bs = 64\n",
    "\n",
    "# model_name = f\"MADtime_pl_FactOnly_SETKS_FreqDoi_CFG_bs{bs}_refine\"\n",
    "# model_name = f\"MADtime_pl_FactOnly_SETKS_FreqDoi_CFG_puncond0.8_bs{bs}_refine\"\n",
    "# model_name = f\"MADtime_FactOnly_SETKS_learnmean_freqdenoise_puncond0.5_bs{bs}_refine\"\n",
    "model_name = \"MADfreq_puncond0.5_bs64_refine\"\n",
    "# model_name = \"MADfreq_FactOnly_puncond0.5_bs64_refine\"\n",
    "# assets/MADfreq_FactOnly_puncond0.5_bs64_refine.csv\n",
    "\n",
    "new_df = pd.read_csv(f\"../assets/{model_name}.csv\")\n",
    "# new_df = pd.read_csv('../assets/MADtime_pl_doublenorm_FreqDenoise.csv')[['MSE']]\n",
    "# print(new_df)\n",
    "new_df = new_df.rename(columns={\"MSE\": model_name})\n",
    "new_df = new_df.drop(columns=[\"CRPS\", \"method\"])\n",
    "df = pd.read_csv(\"../assets/results_MSE.csv\", delimiter=\"\\t\")\n",
    "# print(df)\n",
    "\n",
    "df = pd.merge(df, new_df)\n",
    "\n",
    "# df = pd.concat([df, new_df], axis=1)\n",
    "df = df.groupby(\"dataset\").mean()\n",
    "# # df\n",
    "# df = df[['Dlinear', 'PatchTST', 'CSDI','D3VAE', 'SSSD', 'TMDM', 'mr-diff','MADtime_freqdenoise_bs128']]\n",
    "df = df[\n",
    "    [\n",
    "        \"PatchTST\",\n",
    "        model_name,\n",
    "    ]\n",
    "]\n",
    "# df = df[['Dlinear', 'PatchTST', 'CSDI', 'SSSD', 'D3VAE','TMDM', 'mr-diff','MADfreq_pl_doublenorm_dp0.3','MADtime_freqdenoise']]\n",
    "df = df.T\n",
    "# df = df.drop(columns=['MFRED']).round(4)\n",
    "# df = df.drop(columns=[\"MFRED\", \"ETTh1\", \"ETTm1\"]).round(4)\n",
    "df = df.round(4)\n",
    "df = pd.concat([df, df.rank().mean(axis=1).round(2)], axis=1)\n",
    "df\n",
    "\n",
    "# print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ECL</th>\n",
       "      <th>ETTh2</th>\n",
       "      <th>ETTm2</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>traffic</th>\n",
       "      <th>weather</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CSDI</th>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.3028</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSSD</th>\n",
       "      <td>0.3216</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.4579</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D3VAE</th>\n",
       "      <td>0.3111</td>\n",
       "      <td>0.4173</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>0.4497</td>\n",
       "      <td>5.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TMDM</th>\n",
       "      <td>0.1881</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mr-diff</th>\n",
       "      <td>0.2357</td>\n",
       "      <td>0.1647</td>\n",
       "      <td>0.1293</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MADfreq_FactOnly_learnmean_bs64_new</th>\n",
       "      <td>0.1891</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.2392</td>\n",
       "      <td>0.1163</td>\n",
       "      <td>0.1375</td>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ECL   ETTh2   ETTm2  Exchange  \\\n",
       "CSDI                                 0.1939  0.1638  0.4720    0.3028   \n",
       "SSSD                                 0.3216  0.3108  0.3565    0.6743   \n",
       "D3VAE                                0.3111  0.4173  0.6497    0.5380   \n",
       "TMDM                                 0.1881  0.1591  0.1253    0.2959   \n",
       "mr-diff                              0.2357  0.1647  0.1293    0.2117   \n",
       "MADfreq_FactOnly_learnmean_bs64_new  0.1891  0.1465  0.1101    0.2392   \n",
       "\n",
       "                                     traffic  weather     0  \n",
       "CSDI                                  0.1883   0.1261  3.33  \n",
       "SSSD                                  0.4579   0.3129  5.17  \n",
       "D3VAE                                 0.8314   0.4497  5.67  \n",
       "TMDM                                  0.1076   0.1380  2.00  \n",
       "mr-diff                               0.1453   0.1506  3.17  \n",
       "MADfreq_FactOnly_learnmean_bs64_new   0.1163   0.1375  1.67  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bs = 64\n",
    "# model_name = f\"MADtime_pl_Full_SETKS_FreqDoi_bs{bs}\"\n",
    "# model_name = f\"MADtime_pl_Full_SETKS_bs{bs}\"\n",
    "# model_name = f\"MADtime_pl_FactOnly_FreqDoi_bs{bs}\"\n",
    "# model_name = \"best_MADtime_pl_FactOnly_FreqDoi\"\n",
    "# model_name = \"MADtime_pl_doublenorm_FreqDenoise\"\n",
    "# model_name = f\"MADfreq_naive_bs{bs}\"\n",
    "# model_name = f\"MADfreq_learnmean_bs{bs}_new\"\n",
    "model_name = \"MADfreq_FactOnly_learnmean_bs64_new\"\n",
    "# model_name = \"MADtime_FactOnly_SETKS_learnmean_freqdenoise_bs64_new\"\n",
    "\n",
    "\n",
    "new_df = pd.read_csv(f\"../assets/{model_name}.csv\")\n",
    "# new_df = pd.read_csv('../assets/.csv')[['MSE']]\n",
    "# print(new_df)\n",
    "new_df = new_df.rename(columns={\"CRPS\": model_name})\n",
    "new_df = new_df.drop(columns=[\"MSE\", \"method\"])\n",
    "df = pd.read_csv(\"../assets/results_CRPS.csv\", delimiter=\"\\t\")\n",
    "# print(df)\n",
    "\n",
    "df = pd.merge(df, new_df)\n",
    "\n",
    "# df = pd.concat([df, new_df], axis=1)\n",
    "df = df.groupby(\"dataset\").mean()\n",
    "df = df[\n",
    "    [\n",
    "        \"CSDI\",\n",
    "        \"SSSD\",\n",
    "        \"D3VAE\",\n",
    "        \"TMDM\",\n",
    "        \"mr-diff\",\n",
    "        # \"MADtime_pl_doublenorm\",\n",
    "        model_name,\n",
    "    ]\n",
    "]\n",
    "# df = df[['Dlinear', 'PatchTST', 'CSDI', 'SSSD', 'D3VAE','TMDM', 'mr-diff','MADfreq_pl_doublenorm_dp0.3','MADtime_freqdenoise']]\n",
    "df = df.T\n",
    "# df = df.drop(columns=['MFRED']).round(4)\n",
    "# df = df.drop(columns=[\"MFRED\", \"ETTh1\", \"ETTm1\"]).round(4)\n",
    "df = df.round(4)\n",
    "df = pd.concat([df, df.rank().mean(axis=1).round(2)], axis=1)\n",
    "df\n",
    "\n",
    "# print(df.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freqdiff310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
