{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import torch\n",
    "from src.utils.fourier import dft, idft\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "# from src.utils.filters import MovingAvg\n",
    "from src.utils.fourier import sphere2complex, complex2sphere\n",
    "\n",
    "# def moving_average_freq_response(N, sample_rate, freq):\n",
    "#     omega = 2 * torch.pi * freq / sample_rate\n",
    "#     # SMA coefficients\n",
    "#     b = np.ones(N)\n",
    "#     a = np.array([N] + [0]*(N-1))\n",
    "\n",
    "#     # Calculate the frequency response\n",
    "#     w, h = scipy.signal.freqz(b, a, worN=omega)\n",
    "#     # w *= sample_rate / (2 * np.pi)                      # Convert from rad/sample to Hz\n",
    "#     return h\n",
    "\n",
    "def moving_average_freq_response(N, sample_rate, freq):\n",
    "    omega = 2 * torch.pi * freq / sample_rate\n",
    "    coeff = torch.exp(-1j * omega * (N - 1) / 2) / N\n",
    "    omega = torch.where(omega == 0, 1e-5, omega)\n",
    "    Hw = coeff * torch.sin(omega * N / 2) / torch.sin(omega / 2)\n",
    "    # Hw = Hw*torch.exp(1j*omega*N)\n",
    "    return Hw\n",
    "\n",
    "# def moving_avg(x, N):\n",
    "#     avg = torch.nn.AvgPool1d(kernel_size=N, stride=1)\n",
    "#     front = x[:, 0:1, :].repeat(1, N // 2, 1)\n",
    "#     end = x[:, -1:, :].repeat(1, N - 1 - N // 2, 1)\n",
    "#     x = torch.cat([front, x, end], dim=1)\n",
    "#     x = avg(x.permute(0, 2, 1))\n",
    "#     x = x.permute(0, 2, 1)\n",
    "#     return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.linspace(0, 4*torch.pi, 200)\n",
    "sample_rate = len(t)/(t.max()-t.min())\n",
    "x = torch.sin(t) + torch.sin(2*t) + 0.3*torch.sin(12*t) - 10\n",
    "x_freq = torch.fft.rfft(x)\n",
    "\n",
    "theta, phi = complex2sphere(x_freq.real, x_freq.imag)\n",
    "\n",
    "freq = torch.fft.rfftfreq(len(t), 1/sample_rate)\n",
    "mag = x_freq.abs()\n",
    "phase = x_freq.angle()\n",
    "phase[torch.abs(phase) < 1] = 0\n",
    "fig, axs = plt.subplots(2)\n",
    "axs[0].plot(t, x)\n",
    "axs[1].plot(freq, x_freq.abs())\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "# axs[2].plot(freq, x_freq.angle())\n",
    "# axs[1].plot(freq, theta)\n",
    "# axs[2].plot(freq, phi)\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manuplate on the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "h = moving_average_freq_response(N, sample_rate=sample_rate, freq=freq)\n",
    "x_freq_new = x_freq * h\n",
    "# x_freq_new = x_freq * h * torch.exp(torch.tensor(-1j*N))\n",
    "mag = x_freq_new.abs()\n",
    "phase = x_freq_new.angle()\n",
    "x_new = torch.fft.irfft(x_freq_new)\n",
    "x_new_avgpool = torch.nn.functional.avg_pool1d(x.reshape(1,1,-1), N,N).permute(0,2,1)\n",
    "fig, axs = plt.subplots(2)\n",
    "# axs[0].plot(x_new)\n",
    "axs[0].plot(t, x_new)\n",
    "# axs[0].scatter(t[N-1::N],x_new[N-1::N])\n",
    "# axs[0].scatter(t[N-1::N], x_new_avgpool.flatten())\n",
    "axs[1].plot(freq, mag)\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "# axs[2].plot(freq, phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "manuplate on the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.filters import MovingAvgTime\n",
    "\n",
    "\n",
    "x_new = MovingAvgTime(N)(x.reshape(1,-1,1))\n",
    "# x_new = np.convolve(np.concatenate([x[-N+1:],x]), np.ones(N)/N, mode='valid')\n",
    "x_freq = torch.fft.rfft(x_new.flatten())\n",
    "freq = torch.fft.rfftfreq(len(t), 1/sample_rate)\n",
    "mag = x_freq.abs()\n",
    "phase = x_freq.angle()\n",
    "\n",
    "# mag = x_freq_new.abs()\n",
    "# phase = x_freq_new.angle()\n",
    "# # print(phase)\n",
    "# x = torch.fft.irfft(x_freq_new)\n",
    "# print(x_new[N//2:-N//2])\n",
    "fig, axs = plt.subplots(3)\n",
    "axs[0].plot(x_new.flatten())\n",
    "axs[1].plot(freq, mag)\n",
    "axs[1].set_yscale('log')\n",
    "# axs[1].set_xscale('log')\n",
    "axs[2].plot(freq, phase)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FreqLinear(torch.nn.Module):\n",
    "    def __init__(self, in_channels, fft_len, kernal_size) -> None:\n",
    "        super().__init__()\n",
    "        self.kernel = torch.nn.Parameter(\n",
    "            torch.complex(\n",
    "                torch.ones(fft_len, kernal_size), torch.zeros(fft_len, kernal_size)\n",
    "            ),\n",
    "            requires_grad=True,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(kernal_size * in_channels , in_channels).to(torch.cfloat)\n",
    "        self.in_channels= in_channels\n",
    "        self.fft_len = fft_len\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0,2,1)\n",
    "        x = torch.fft.rfft(x, norm=\"ortho\", dim=1)\n",
    "        x_channels = []\n",
    "        for i in range(x.shape[-1]):\n",
    "            x_channels.append(x[...,[i]] * self.kernel)\n",
    "        x = torch.concat(x_channels, dim=-1)\n",
    "        x = self.linear(x)\n",
    "        # x = self.linear(x.flatten()).reshape(-1, self.fft_len, self.in_channels)\n",
    "        x = torch.fft.irfft(x, norm=\"ortho\", dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TimeConv(torch.nn.Module):\n",
    "    def __init__(self, in_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channel, out_channels=in_channel, kernel_size=3, bias=False, padding=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.permute(0,2,1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "x = torch.sin(torch.arange(288) / 100).reshape(1, -1, 2)\n",
    "m = FreqLinear(in_channels=x.shape[-1], fft_len=x.shape[1]//2+1, kernal_size=10)\n",
    "for p in m.parameters():\n",
    "    print(p.numel())\n",
    "y = torch.ones_like(x)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "loss = loss_fn(y, m(x))\n",
    "loss.backward()\n",
    "\n",
    "# x = x.repeat(2,1,1)\n",
    "# kernel = torch.rand(x.shape[1] // 2 + 1, 3)\n",
    "# x = torch.fft.rfft(x, dim=1)\n",
    "# print(x)\n",
    "# print(kernel)\n",
    "# print(x.shape)\n",
    "# print(kernel.shape)\n",
    "# x * kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def moving_average_1d(data: torch.Tensor, kernel_size:int, stride:int=1):\n",
    "    # Unfold the data tensor to create a windowed view\n",
    "    unfolded_data = data.unfold(1, kernel_size, stride)\n",
    "    print(unfolded_data.shape)\n",
    "    \n",
    "    # Create a kernel tensor for matrix multiplication\n",
    "    kernel = torch.ones(kernel_size) / kernel_size\n",
    "    \n",
    "    # Perform matrix multiplication\n",
    "    moving_averages_unfolded = unfolded_data @ kernel\n",
    "    \n",
    "    # # Pad the moving averages tensor to match the original data size\n",
    "    # padding = kernel_size - 1\n",
    "    # moving_averages_padded = torch.cat((torch.zeros(padding), moving_averages_unfolded))\n",
    "    \n",
    "    # Fold the moving averages tensor to get the final result\n",
    "    # moving_averages = moving_averages_padded.view(-1)\n",
    "    \n",
    "    return moving_averages_unfolded\n",
    "\n",
    "# Example usage\n",
    "data = torch.arange(60).float().reshape(2,-1,3)  # 1D tensor with 10 elements\n",
    "kernel_size = 5\n",
    "\n",
    "moving_averages = moving_average_1d(data, kernel_size)\n",
    "print(moving_averages)  # Output: torch.Size([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.schedules.collection import linear_schedule\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "from src.utils.fourier import complex2sphere, sphere2complex\n",
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "\n",
    "\n",
    "# x_norm_fft = torch.fft.rfft(x_norm, dim=1, norm=\"ortho\")\n",
    "# plt.plot(dct(x, norm='ortho').flatten())\n",
    "# plt.yscale('log')\n",
    "\n",
    "# x_norm = (x - x.mean(dim=1)) / torch.sqrt(x.var(dim=1))\n",
    "freq = torch.fft.rfftfreq(x.shape[1])\n",
    "print(freq.shape)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(torch.concat([x_fft.real, x_fft.imag[:,1:-1,:]], dim=1).flatten())\n",
    "# fig.savefig(\"noisy_0.png\")\n",
    "# plt.close()\n",
    "\n",
    "mat = [MovingAvgFreq(i, freq=freq).Hw for i in range(2, x.shape[1] + 1)]\n",
    "mat = torch.concat(mat)\n",
    "fig, axs = plt.subplots(2)\n",
    "for i in range(len(freq)):\n",
    "    axs[0].plot(mat[:,i,:].real)\n",
    "    axs[1].plot(mat[:,i,:].imag)\n",
    "    \n",
    "    \n",
    "# mat = [MovingAvgTime(i) for i in range(2, x.shape[1] + 1)]\n",
    "# T = len(mat)\n",
    "# _, _, alpha_bars = linear_schedule(0, 0, T)\n",
    "# betas = torch.sqrt(1 - alpha_bars)\n",
    "# betas\n",
    "\n",
    "# plt.plot(betas)\n",
    "# for i, degrade_fn in enumerate(mat):\n",
    "#     # x_noisy = degrade_fn(x)\n",
    "#     x_noisy = degrade_fn(x_fft) + torch.randn_like(x_fft) * betas[i]\n",
    "#     # x_noisy = degrade_fn(x) + torch.randn_like(x) * betas[i]\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ax.plot(torch.concat([x_noisy.real, x_noisy.imag[:,1:-1,:]], dim=1).flatten())\n",
    "#     fig.savefig(f\"noisy_{i+1}.png\")\n",
    "#     plt.close()\n",
    "#     # if i == (T - 1):\n",
    "#     #     print(norm.fit(x_noisy.numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from src.utils.fourier import dft, idft\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Generate a random time-domain signal\n",
    "N = 1000  # Number of samples\n",
    "\n",
    "# signal = 2 * torch.sin(torch.linspace(0, 10, 1000))\n",
    "# signal = torch.randn(N)\n",
    "# signal = 2 * torch.sin(torch.linspace(0, 10, N))  + torch.randn(N) + 10\n",
    "signal = x.flatten()\n",
    "N = len(signal)\n",
    "print(torch.std(signal, unbiased=False))\n",
    "signal_norm = (signal - torch.mean(signal)) / torch.std(signal, unbiased=False)\n",
    "print(signal_norm[:10])\n",
    "plt.plot(signal)\n",
    "\n",
    "# Compute the DFT of the signal using PyTorch's rfft function with norm='ortho'\n",
    "# x_fft = torch.fft.rfft(signal, norm='ortho')\n",
    "x_fft = dft(signal.reshape(1,-1,1), real_imag=True).flatten()\n",
    "print(torch.std(x_fft, unbiased=False))\n",
    "# plt.plot(x_fft * 2**0.5)\n",
    "\n",
    "\n",
    "# Calculate the mean from the DFT coefficients\n",
    "mean = x_fft[0].real\n",
    "mean_minus = torch.concat([mean.reshape(-1,1), torch.zeros(len(x_fft)-1, 1)]).flatten()\n",
    "\n",
    "# Calculate the variance and standard deviation from the DFT coefficients\n",
    "energy_freq = torch.sum(torch.abs(x_fft[1:])**2) * 2 # Account for orthogonal normalization and one-sided representation\n",
    "adjusted_energy = energy_freq\n",
    "variance = adjusted_energy / (N)\n",
    "std_dev = torch.sqrt(variance)\n",
    "signal_fft_norm = (x_fft - mean_minus) / std_dev\n",
    "# inv_signal_fft_norm = torch.fft.irfft(signal_fft_norm, norm='ortho')\n",
    "inv_signal_fft_norm = idft(signal_fft_norm.reshape(1, -1, 1), real_imag=True).flatten()\n",
    "print(inv_signal_fft_norm[:10])\n",
    "# plt.plot(inv_signal_fft_norm)\n",
    "(inv_signal_fft_norm - signal_norm).max()\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Mean (Time Domain):\", torch.mean(signal).item())\n",
    "# print(\"Mean (Frequency Domain):\", mean.item())\n",
    "# print(\"Standard Deviation (Time Domain):\", torch.std(signal).item())\n",
    "# print(\"Standard Deviation (Frequency Domain):\", std_dev.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from src.schedules.collection import linear_schedule, cosine_schedule\n",
    "from src.utils.filters import MovingAvgFreq, MovingAvgTime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "freq = torch.fft.rfftfreq(x.shape[1])\n",
    "x_freq = torch.fft.rfft(x, dim=1, norm='ortho')\n",
    "kernel_size = 10\n",
    "\n",
    "maf = MovingAvgFreq(kernel_size, freq=freq)\n",
    "x_freq_flt = maf(x_freq)\n",
    "x_freq_flt = torch.fft.irfft(x_freq_flt, dim=1, norm='ortho')[:,kernel_size-1::kernel_size,:]\n",
    "x_time_flt = torch.nn.functional.avg_pool1d(x.permute(0,2,1), kernel_size, kernel_size)\n",
    "plt.plot(x_freq_flt.flatten())\n",
    "plt.plot(x_time_flt.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from src.utils.filters import MovingAvgTime, MovingAvgFreq\n",
    "from src.utils.fourier import complex2sphere, sphere2complex\n",
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")[[\"value\"]]\n",
    "df = df[:288]\n",
    "kernel_size = 10\n",
    "# x = torch.randn(12).reshape(1, -1, 1)\n",
    "x = torch.from_numpy(df.values).reshape(1, -1, 1)\n",
    "mat = MovingAvgTime(kernel_size)\n",
    "x_down_real = mat(x)\n",
    "mat_stride = torch.nn.AvgPool1d(kernel_size, kernel_size)\n",
    "x_down_real_stride = mat_stride(x.permute(0, 2, 1))\n",
    "\n",
    "rec = torch.nn.functional.interpolate(\n",
    "    x_down_real.reshape(1, 1, -1), size=x.shape[1] - kernel_size + 1, mode='nearest-exact'\n",
    ")\n",
    "real = x_down_real_stride.flatten()\n",
    "plt.plot(rec[0,0,::kernel_size])\n",
    "plt.plot(real.flatten())\n",
    "((rec[0,0,::kernel_size] - real.flatten())**2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(12).reshape(1, -1, 1).float()\n",
    "avg = torch.nn.AvgPool1d(3,3)\n",
    "a_avg = avg(a.permute(0,2,1)).permute(0,2,1)\n",
    "\n",
    "mean = torch.mean(a, dim=1, keepdim=True)\n",
    "stdev = torch.sqrt(torch.var(a, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
    "a_norm = (a - mean) / stdev\n",
    "a_norm_avg = avg(a_norm.permute(0,2,1)).permute(0,2,1)\n",
    "torch.allclose(a_norm_avg*stdev + mean, a_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.arange(16).float()\n",
    "\n",
    "a_fft_norm = torch.fft.rfft(a, norm='ortho')\n",
    "\n",
    "k1 = 12\n",
    "k2 = -2\n",
    "\n",
    "print(a_fft_norm)\n",
    "b = k1 * a + k2\n",
    "print(b)\n",
    "b_fft = a_fft_norm.clone() \n",
    "b_fft = b_fft * k1\n",
    "b_fft[0] += k2 * len(a) ** 0.5 \n",
    "print(b_fft)\n",
    "# print(b_fft)\n",
    "# print(b)\n",
    "print(torch.fft.irfft(b_fft, norm='ortho'))\n",
    "# torch.allclose(4*a, torch.fft.irfft(a_fft * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils.schedule import linear_schedule, cosine_schedule\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_,_,_,a = linear_schedule(1e-4, 1e-2, 288)\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ks = 100\n",
    "# a = torch.sin(torch.linspace(0, torch.pi * 2, 1000)).float()\n",
    "# a = a + torch.randn_like(a) * 0.1\n",
    "a = torch.arange(100000).float()\n",
    "a_std, a_mean = torch.std_mean(a)\n",
    "print(a_std, a_mean)\n",
    "a = torch.nn.functional.avg_pool1d(a.reshape(1, 1, -1), ks, 1).flatten()\n",
    "a_std, a_mean = torch.std_mean(a)\n",
    "print(a_std, a_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 1000\n",
    "a = torch.sin(torch.linspace(0, 100, N)) + torch.exp(torch.linspace(0, 100, N) / 50)\n",
    "\n",
    "plt.plot(a)\n",
    "a_fft = torch.fft.rfft(a)\n",
    "print(a_fft[0])\n",
    "# plt.plot(a_fft.real)\n",
    "# plt.plot(a_fft.imag)\n",
    "noise = torch.randn(N)\n",
    "a = a + noise\n",
    "plt.plot(a)\n",
    "a_fft = torch.fft.rfft(a)\n",
    "print(a_fft[0])\n",
    "print(torch.fft.rfft(noise)[0])\n",
    "# plt.plot(a_fft.real)\n",
    "# plt.plot(a_fft.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_freq = pd.read_csv('../assets/MADFreq_fast_dtm.csv', index_col=0)\n",
    "# df_time = pd.read_csv('../assets/MADTime_fast_dtm_old.csv', index_col=0)\n",
    "df_time = pd.read_csv('../assets/MADTime_fast_dtm_20240621013629.csv', index_col=0)\n",
    "df = pd.concat([df_freq, df_time])\n",
    "df = df.reset_index(drop=True)\n",
    "# df = df[df['method'].str.contains('MLPBackbone_freq_norm_True_diff_True')]\n",
    "df[df['granularity']==1].sort_values('RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../assets/fast_dtm.csv', index_col=0)\n",
    "df[df['granularity']==1].sort_values('RMSE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils.schedule import linear_schedule, cosine_schedule\n",
    "\n",
    "var_schedule = torch.load(\"/home/user/data/FrequencyDiffusion/savings/mfred/std_schedule.pt\")\n",
    "# print(var_schedule)\n",
    "var_schedule = torch.sqrt(1 - var_schedule**2)\n",
    "# # torch.save(torch.sqrt(1 - var_schedule**2), \"/home/user/data/FrequencyDiffusion/savings/empirical_schedule.pt\")\n",
    "# betas = linear_schedule(1e-4, 2e-2, len(var_schedule))[-1]\n",
    "plt.plot(var_schedule, label=\"empirical\")\n",
    "\n",
    "var_schedule = 1 / torch.arange(2, 289)\n",
    "var_schedule = torch.sqrt(1 - var_schedule)\n",
    "plt.plot(var_schedule, label='approx')\n",
    "# torch.save(betas, \"/home/user/data/FrequencyDiffusion/savings/ddpm_schedule.pt\")\n",
    "# betas = cosine_schedule(len(var_schedule))[-1]\n",
    "# plt.plot(betas, label=\"cosine\")\n",
    "# # torch.save(betas, \"/home/user/data/FrequencyDiffusion/savings/cosine_schedule.pt\")\n",
    "\n",
    "# # plt.plot(var_schedule, label='std_ratio')\n",
    "# # plt.plot(1 - var_schedule, label=\"1-sr\")\n",
    "# # plt.plot(torch.sqrt(1 - var_schedule), label=\"$\\sqrt{1-sr}$\")\n",
    "# plt.plot(var_schedule, label=\"$\\sqrt{1-sr^2}$\")\n",
    "# # plt.plot(betas, label=\"cosine\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('/home/user/data/FrequencyDiffusion/savings/mfred/benchmarks/bench_metrics.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "print(results)\n",
    "keys = results[0].keys()\n",
    "all_results = {k:[] for k in keys}\n",
    "for r in results:\n",
    "    for k in keys:\n",
    "        all_results[k].append(r[k])\n",
    "for k in keys:\n",
    "    metrics = all_results[k]\n",
    "    metrics = np.array(metrics)\n",
    "    print(k)\n",
    "    print(metrics.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/user/data/FrequencyDiffusion/dataset/MFRED_clean.csv', index_col=0, parse_dates=True)\n",
    "df = df.drop(columns=['weekday', 'hour'])\n",
    "df.to_csv('/home/user/data/FrequencyDiffusion/dataset/MFRED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from src.datamodule.data_loader import Dataset_Custom, Dataset_ETT_hour\n",
    "\n",
    "dl = Dataset_ETT_hour(\n",
    "    None,\n",
    "    root_path=\"/home/user/data/THU-timeseries/ETT-small/\",\n",
    "    # root_path=\"/home/user/data/FrequencyDiffusion/dataset/\",\n",
    "    data_path=\"ETTh1.csv\",\n",
    "    # data_path=\"MFRED.csv\",\n",
    "    flag=\"test\",\n",
    "    size=[96, 48, 96],\n",
    "    freq=\"h\", scale=False\n",
    ")\n",
    "dl = DataLoader(dl, batch_size=128, shuffle=False, drop_last=True)\n",
    "for batch in dl:\n",
    "    seq_x, seq_y, seq_x_mark, seq_y_mark = batch\n",
    "    print(seq_x.shape)\n",
    "    print(seq_x[0, :10])\n",
    "    print(seq_y[0, -96:])\n",
    "    print(seq_x_mark[0,:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamodule.dataset import mfred\n",
    "import yaml\n",
    "\n",
    "data_config = yaml.safe_load(open('../configs/mfred.yaml'))\n",
    "data_config['scale'] = False\n",
    "train_dl, val_dl, test_dl, y_scaler = mfred(data_config)\n",
    "for batch in test_dl:\n",
    "    seq_x = batch['observed_data']\n",
    "    seq_y = batch['future_data']\n",
    "    print(seq_x[0, :10])\n",
    "    print(seq_y[0, :10])\n",
    "    # print(seq_x_mark)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.loader import TrainDataLoader\n",
    "from gluonts.dataset.split import split\n",
    "import pandas as pd\n",
    "from gluonts.torch.batchify import batchify, stack\n",
    "from gluonts.dataset.repository.datasets import get_dataset\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "import numpy as np\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "print(f\"Available datasets: {dataset_names}\")\n",
    "dataset = get_dataset(\"electricity_nips\")\n",
    "print(len(dataset.test))\n",
    "print(len(dataset.train))\n",
    "dataset.metadata.feat_static_cat[0].cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from gluonts.dataset.repository import get_dataset, dataset_names\n",
    "from gluonts.dataset.util import to_pandas\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch import SimpleFeedForwardEstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions\n",
    "from gluonts.evaluation import Evaluator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generate_single_ts(date_range, item_id=None) -> pd.DataFrame:\n",
    "    \"\"\"create sum of `n_f` sin/cos curves with random scale and phase.\"\"\"\n",
    "    n_f = 2\n",
    "    period = np.array([24 / (i + 1) for i in range(n_f)]).reshape(1, n_f)\n",
    "    scale = np.random.normal(1, 0.3, size=(1, n_f))\n",
    "    phase = 2 * np.pi * np.random.uniform(size=(1, n_f))\n",
    "    periodic_f = lambda x: scale * np.sin(np.pi * x / period + phase)\n",
    "\n",
    "    t = np.arange(0, len(date_range)).reshape(-1, 1)\n",
    "    target = periodic_f(t).sum(axis=1) + np.random.normal(0, 0.1, size=len(t))\n",
    "    ts = pd.DataFrame({\"target\": target}, index=date_range)\n",
    "    if item_id is not None:\n",
    "        ts[\"item_id\"] = item_id\n",
    "    return ts\n",
    "\n",
    "prediction_length, freq = 24, \"1H\"\n",
    "T = 10 * prediction_length\n",
    "date_range = pd.date_range(\"2021-01-01\", periods=T, freq=freq)\n",
    "ts = generate_single_ts(date_range)\n",
    "\n",
    "print(\"ts.shape:\", ts.shape)\n",
    "print(ts.head())\n",
    "ts.loc[:, \"target\"].plot(figsize=(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.torch import DeepAREstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "\n",
    "\n",
    "def train_and_predict(dataset, estimator):\n",
    "    predictor = estimator.train(dataset)\n",
    "    forecast_it, ts_it = make_evaluation_predictions(\n",
    "        dataset=dataset, predictor=predictor\n",
    "    )\n",
    "    evaluator = Evaluator(quantiles=(np.arange(20) / 20.0)[1:], num_workers=0)\n",
    "    agg_metrics, item_metrics = evaluator(ts_it, forecast_it, num_series=len(dataset))\n",
    "    return agg_metrics[\"MSE\"]\n",
    "\n",
    "\n",
    "estimator = DeepAREstimator(\n",
    "    freq=freq, prediction_length=prediction_length, trainer_kwargs={'max_steps':3,'accelerator':'cpu',})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.pandas import PandasDataset\n",
    "\n",
    "ds = PandasDataset(ts, target=\"target\", freq=freq)\n",
    "train_and_predict(ds, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 10\n",
    "multiple_ts = [generate_single_ts(date_range) for i in range(N)]\n",
    "\n",
    "ds = PandasDataset(multiple_ts, target=\"target\", freq=freq)\n",
    "train_and_predict(ds, estimator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_in_long_format = pd.concat(\n",
    "    [generate_single_ts(date_range, item_id=i) for i in range(N)]\n",
    ")\n",
    "# ts_in_long_format\n",
    "\n",
    "# # Note we need an item_id column now and provide its name to the constructor.\n",
    "# # Otherwise, there is no way to distinguish different time series.\n",
    "ds = PandasDataset.from_long_dataframe(\n",
    "    ts_in_long_format, item_id=\"item_id\", target=\"target\", freq=freq\n",
    ")\n",
    "train_and_predict(ds, estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_ts_with_features(date_range, item_id) -> pd.DataFrame:\n",
    "    ts = generate_single_ts(date_range, item_id)\n",
    "    T = ts.shape[0]\n",
    "    # static features are constant for each series\n",
    "    ts[\"dynamic_real_1\"] = np.random.normal(size=T)\n",
    "    ts[\"dynamic_real_2\"] = np.random.normal(size=T)\n",
    "    # ... we can have as many static or dynamic features as we like\n",
    "    return ts\n",
    "\n",
    "\n",
    "ts = generate_single_ts_with_features(date_range, item_id=0)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_with_features = DeepAREstimator(\n",
    "    freq=ds.freq,\n",
    "    prediction_length=prediction_length,\n",
    "    num_feat_dynamic_real=2,\n",
    "    num_feat_static_cat=1,\n",
    "    num_feat_static_real=1,\n",
    "    cardinality=[\n",
    "        3,\n",
    "    ],\n",
    "    trainer_kwargs={'max_steps':3,'accelerator':'cpu',}\n",
    "    # trainer=Trainer(epochs=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_ts = {\n",
    "    i: generate_single_ts_with_features(date_range, item_id=i) for i in range(N)\n",
    "}\n",
    "static_features = pd.DataFrame(\n",
    "    {\n",
    "        \"color\": pd.Categorical(np.random.choice([\"red\", \"green\", \"blue\"], size=N)),\n",
    "        \"height\": np.random.normal(loc=100, scale=15, size=N),\n",
    "    },\n",
    "    index=list(multiple_ts.keys()),\n",
    ")\n",
    "multiple_ts_long = pd.concat(multiple_ts.values())\n",
    "\n",
    "multiple_ts_dataset = PandasDataset(\n",
    "    multiple_ts,\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "# for long-dataset we use a different constructor and need a `item_id` column\n",
    "multiple_ts_long_dataset = PandasDataset.from_long_dataframe(\n",
    "    multiple_ts_long,\n",
    "    item_id=\"item_id\",\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "static_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_predict(multiple_ts_dataset, estimator_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_predict(multiple_ts_long_dataset, estimator_with_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = PandasDataset(\n",
    "    {item_id: df[:-3*prediction_length] for item_id, df in multiple_ts.items()},\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")\n",
    "\n",
    "test = PandasDataset(\n",
    "    multiple_ts,\n",
    "    feat_dynamic_real=[\"dynamic_real_1\", \"dynamic_real_2\"],\n",
    "    static_features=static_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator_with_features.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.split import split\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.util import period_index, to_pandas\n",
    "\n",
    "\n",
    "def _to_dataframe(input_label) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Turn a pair of consecutive (in time) data entries into a dataframe.\n",
    "    \"\"\"\n",
    "    start = input_label[0][FieldName.START]\n",
    "    targets = [entry[FieldName.TARGET] for entry in input_label]\n",
    "    full_target = np.concatenate(targets, axis=-1)\n",
    "    index = period_index({FieldName.START: start, FieldName.TARGET: full_target})\n",
    "    return pd.DataFrame(full_target.transpose(), index=index)\n",
    "\n",
    "\n",
    "window_length = predictor.prediction_length + predictor.lead_time\n",
    "# print(predictor.lead_time)\n",
    "training_data, test_template = split(test, offset=-3 * window_length)\n",
    "test_data = test_template.generate_instances(window_length, windows=2 * window_length + 1, distance=1, max_history=window_length)\n",
    "forecast_it, ts_it = (\n",
    "    predictor.predict(test_data.input, num_samples=100),\n",
    "    map(_to_dataframe, test_data),\n",
    ")\n",
    "forecasts_pytorch = list(forecast_it)\n",
    "tss_pytorch = list(ts_it)\n",
    "\n",
    "evaluator = Evaluator(quantiles=(np.arange(20) / 20.0)[1:], num_workers=0)\n",
    "agg_metrics, item_metrics = evaluator(tss_pytorch, forecasts_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "\n",
    "for idx, (forecast, ts) in islice(enumerate(zip(forecasts_pytorch, tss_pytorch)), 9):\n",
    "    # ax = plt.subplot(3, 3, idx + 1)\n",
    "    print(ts[-5 * prediction_length :].to_timestamp())\n",
    "    print(forecast)\n",
    "    # plt.plot(ts[-5 * prediction_length :].to_timestamp(), label=\"target\")\n",
    "    # forecast.plot()\n",
    "    # plt.xticks(rotation=60)\n",
    "    # ax.xaxis.set_major_formatter(date_formater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "model_a = torch.load(\"/mnt/ExtraDisk/wcx/research/FrequencyDiffusion/savings_newcond/etth1_96_S/MADFreq/diffusion_0.pt\")\n",
    "model_b = torch.load(\"/mnt/ExtraDisk/wcx/research/FrequencyDiffusion/savings/etth1_96_S/MADFreq/MLPBackbone_freq_norm_True_diff_True_std_fcsth_96_0/diffusion.pt\")\n",
    "for pa, pb in zip(model_a.parameters(), model_b.parameters()):\n",
    "    print(pa.shape == pb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3345-0.2586j, -0.3197-0.1523j, -0.4801-0.4048j, -0.3056-0.0415j,\n",
       "        -0.2492+0.0830j, -0.0292+0.1516j, -0.3060+0.0791j,  0.5165-0.1692j,\n",
       "         0.1668-0.7006j, -0.2433-0.0151j])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a =torch.randn(10, dtype=torch.cfloat)\n",
    "fn = torch.nn.functional.silu\n",
    "fn(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d50082ca3605edaedbc537b9ac34a583897f1c451fa7fce6362ff0a321b45ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
